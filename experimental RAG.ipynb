{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG System for Job Listings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Practice vector database creation/adding new documents\n",
    "    - Include some sort of `rank` metadata \n",
    "        - Manual/Other Resumes =  Rank 1 \n",
    "        - ApplyAll = Rank 2\n",
    "- Implement self-querying RAG \n",
    "    - See if can combine query transformations WITH self-querying RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma, FAISS\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "import pandas as pd\n",
    "import glob, os, sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import app_functions as af"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 260)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_pds = glob.glob('data/Other/*.pdf')\n",
    "applyall_pds = glob.glob('data/ApplyAll/*.pdf')\n",
    "len(manual_pds), len(applyall_pds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/Other/LinkedIn- AI & ML Engineer _ BDO USA _ LinkedIn.pdf'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pdf = manual_pds[-1] \n",
    "test_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI & ML Engineer\n",
      "$100K/yr - $155K/yr···Mid-Senior level\n",
      "Machine Learning·Python·Show more\n",
      "10,001+ employees · Accounting\n",
      "1 school alum works here\n",
      "Skills: Artificial Intelligence (AI), Pattern Recognition, +8 more\n",
      "Apply SaveBDO USA· Columbia, MD ·1 month ago·28 applicants\n",
      "HybridFull-time\n",
      "Am I a good fit for this job? How can I best position myself fo\n",
      "About the job\n",
      "Job Description\n",
      "Job Summary:\n",
      "With a global network serving clients across multiple industries and countries, our\n",
      "analytics game changers are poised for widespread technological impact. Our\n",
      "industry-recognized team is in high demand across data analytics, robotic\n",
      "process automation, and artificial intelligence. We gravitate towards bright\n",
      "individuals who value impactful change, worldly purpose, and a personal\n",
      "connection with diverse innovators. This role allows you to work with a team of\n",
      "talented consultants, requiring you to balance innovation with pragmatic client\n",
      "expectation management. With our team, you will be challenged \n"
     ]
    }
   ],
   "source": [
    "print(af.read_pdf(test_pdf)[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='AI & ML Engineer\\n$100K/yr - $155K/yr···Mid-Senior level\\nMachine Learning·Python·Show more\\n10,001+ employees · Accounting\\n1 school alum works here\\nSkills: Artificial Intelligence (AI), Pattern Recognition, +8 more\\nApply SaveBDO USA· Columbia, MD ·1 month ago·28 applicants\\nHybridFull-time\\nAm I a good fit for this job? How can I best position myself fo\\nAbout the job\\nJob Description\\nJob Summary:\\nWith a global network serving clients across multiple industries and countries, our\\nanalytics game changers are poised for widespread technological impact. Our\\nindustry-recognized team is in high demand across data analytics, robotic\\nprocess automation, and artificial intelligence. We gravitate towards bright\\nindividuals who value impactful change, worldly purpose, and a personal\\nconnection with diverse innovators. This role allows you to work with a team of\\ntalented consultants, requiring you to balance innovation with pragmatic client\\nexpectation management. With our team, you will be challenged to build scalable\\nsolutions, while embracing a fail-forward mentality critical to evolution. Whether\\nyouʼre telling a data story in ways our clients never imagined or building advanced\\nAI models with automated data engineering, the core purpose will be centered on\\nusing data to impact people in a meaningful way.\\nThis position will work with cutting edge technology, deliver high quality solutions\\nacross various industries and collaborate with teams on engagements that range\\nin size and scope. This position will receive continuous career development\\nopportunities, given the size and potential of client engagements. This role will\\nperform hands-on delivery of solutions that include artificial intelligence (AI) and\\ncognitive services, ML models, pipelines, databases, and other data analytics\\ncomponents, contributing to the development and unit testing of solutions.\\nJob Duties\\nDesigns, and implements best in class solutions that include AI and\\ncognitive services, ML models, data ingestion strategies, semantic layers\\nand models, visualizations, streaming processes, API integrations, and\\nautomation (RPA) solutions for end-to-end data analytics solutions on\\nprimarily, but not limited to, cloud analytics platforms such as Azure and\\nAWS\\nListens to client needs to align solutions with business requirements and\\ndelivery schedules\\nCreates written functional and technical designs\\nParticipates in project status and stand meetings, and assists with\\nproviding aggregated project status for project and program managersHomeMy NetworkJobsMessagingNotificationsMe\\n For BusinessLear\\n2 1254/24/24, 1:54 PM (28) AI & ML Engineer | BDO USA | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3866911336/?eBP=CwEAAAGPET5Ue5oWGLmsFkyeWdZDoeYDvLIc3hupUJ92igPK7glibsZwKciq-ZSSXOWN7Wn7IeE24… 1/9', metadata={'source': 'data/Other/LinkedIn- AI & ML Engineer _ BDO USA _ LinkedIn.pdf', 'page': 0}),\n",
       " Document(page_content='Assists with SLA compliance of solutions, and performs performance\\ntuning and optimization efforts of end-to-end solutions\\nWrites code using multiple languages and correctly applies frameworks,\\narchitectural patterns, and software development principles\\nDelivers high-performance, scalable, repeatable, and secure deliverables\\nwith broad impact (high throughput and low latency)\\nAssists with implementation of governance programs and best practices\\nPerforms the cleaning and transforming of data from source systems into\\nanalytics models\\nImplements models to support data visualizations and integrations\\nAssists with implementing MLOps, DevOps, DataOps, methodologies on\\nprojects\\nWrites custom integration logic in applicable programming languages\\nAssists project managers with work breakdown structure creation,\\nproject estimation, resource staffing, workload planning and adjustments\\nthroughout the project lifecycle\\nAssists clients with licensing, security, and cost estimation of solutions\\nPerforms code reviews to ensure adherence to standards\\nWorks directly with clients and team members to establish secure data\\nanalytics platforms and infrastructure\\nContributes to successful deployments of developed solutions and\\nintegration of DevOps and MLOps tools\\nMaintains a broad and current understanding of data analytics and\\nbusiness intelligence strategies, cloud platforms, methodologies, and\\ntools\\nBuilds client relationships during project execution, effectively becoming\\na trusted advisor of the client\\nParticipates in support activities for existing software solutions\\nOther duties as assigned\\nSupervisory Responsibilities\\nSupervises the day-to-day workload of Associates on assigned\\nengagements to ensure that timelines and deliverables are met, and\\nreviews work product\\nEducation\\nQualifications, Knowledge, Skills, and Abilities:\\nHigh School Diploma or GED equivalent, required\\nBachelorʼs degree, preferred; focus in Information Systems, Data Science\\nor Computer Science, preferred\\nExperience\\nFive ( 5 ) or more years of experience within Artificial Intelligence , Data\\nAnalytics, Business Intelligence, Machine Learning, Application\\nDevelopment, required\\nOne ( 1 ) or more years of experience technically leading development\\nprojects, preferred\\nOne ( 1 ) or more years of consulting experience or implementation of\\ncloud-based data analytics solutions, preferred\\nLicense/Certifications\\nN/A\\nSoftware\\nStrong experience with AI/ML model lifecycle, required\\nStrong SQL skills including Data Definition Language (DDL), Data\\nManipulation Language (DML), views, functions, stored procedures, or\\nperformance tuning, required\\nExperience with Data Warehousing, Data Modeling, Semantic Model\\nDefinition or Star Schema Construction, required\\nExperience with AI & ML Platforms such as Azure Cognitive Services or\\nAWS SageMaker & ML Services, required4/24/24, 1:54 PM (28) AI & ML Engineer | BDO USA | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3866911336/?eBP=CwEAAAGPET5Ue5oWGLmsFkyeWdZDoeYDvLIc3hupUJ92igPK7glibsZwKciq-ZSSXOWN7Wn7IeE24… 2/9', metadata={'source': 'data/Other/LinkedIn- AI & ML Engineer _ BDO USA _ LinkedIn.pdf', 'page': 1}),\n",
       " Document(page_content='Hands on delivery experience of end-to-end cloud data analytics\\nsolutions within Azure or AWS, preferred\\nExperience with one (1) or more of the following computer languages,\\npreferred:\\nC#\\nC++\\nPython\\nJava\\nScala\\nExperience with tabular modeling within Power BI or Azure Analysis\\nServices, preferred\\nExperience with Git, DevOps, and MLOps deployment technologies,\\npreferred\\nExperience with Linux, preferred\\nExperience with one (1) or more of the following, preferred:\\nAI Algorithms/Machine Learning\\nComputer Vision based AI technologies\\nLanguage\\nN/A\\nOther Knowledge, Skills & Abilities\\nAbility to work with a high degree of professionalism and autonomy\\nExcellent verbal and written communication skills\\nSolid organizational skills, especially the ability to meet project deadlines\\nwith a focus on details\\nAbility to successfully multi-task while working independently or within a\\ngroup environment\\nAbility to work in a deadline-driven environment, and handle multiple\\nprojects simultaneously\\nAbility to interact effectively with people at all organizational levels of the\\nFirm\\nAbility to effectively interact with a team of professionals and delegating\\nwork assignments, as needed\\nAbility to build and maintain strong relationships with internal and client\\npersonnel\\nKeywords:Data Analytics, Business Intelligence, BI, Solution Architect, Data\\nArchitect, Synapse, IoT, Machine Learning, PyTorch, TensorFlow, Data Lake,\\nStream, Cube, Microsoft, SQL Server, Tableau, .Net, C#, Qlik, Power BI, Machine\\nLearning, Azure Data Factory, RedShift, UiPath, Cloud, RPA, AWS, Redshift,\\nKinesis, QuickSight, SageMaker, S3, Databricks, AWS Lake Formation, Snowflake,\\nPython, Qlik, Athena, Data Pipeline, Glue, Star Schema, Data Modeling,\\nPerformance Tuning, SQL\\nIndividual salaries that are offered to a candidate are determined after\\nconsideration of numerous factors including but not limited to the candidateʼs\\nqualifications, experience, skills, and geography.\\nCalifornia Range: $100,000 - $155,000\\nColorado Range: $100,000 - $155,000\\nNYC/Long Island/Westchester Range: $100,000 - $155,000\\nWashington Range: $100,000 - $155,000\\nAbout Us\\nJoin us at BDO, where you will find more than a career, youʼll find a place where\\nyour work is impactful, and you are valued for your individuality. We offer\\nflexibility and opportunities for advancement. Our culture is centered around\\nmaking meaningful connections, approaching interactions with curiosity, and\\nbeing true to yourself, all while making a positive difference in the world.\\nAt BDO, our purpose of helping people thrive every day is at the heart of\\neverything we do. Together, we are focused on delivering exceptional and\\nsustainable outcomes and value for our people, our clients, and our communities.\\nBDO is proud to be an ESOP company, reflecting a culture that puts people first,\\nby sharing financially in our growth in value with our U.S. team. BDO professionals4/24/24, 1:54 PM (28) AI & ML Engineer | BDO USA | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3866911336/?eBP=CwEAAAGPET5Ue5oWGLmsFkyeWdZDoeYDvLIc3hupUJ92igPK7glibsZwKciq-ZSSXOWN7Wn7IeE24… 3/9', metadata={'source': 'data/Other/LinkedIn- AI & ML Engineer _ BDO USA _ LinkedIn.pdf', 'page': 2}),\n",
       " Document(page_content='See lessprovide assurance, tax and advisory services for a diverse range of clients across\\nthe U.S. and in over 160 countries through our global organization.\\nBDO is the first large accounting and advisory organization to implement an\\nEmployee Stock Ownership Plan (ESOP). A qualified retirement plan, the ESOP\\noffers participants a stake in the firmʼs success through beneficial ownership and\\na unique opportunity to enhance their financial well-being. The ESOP stands as a\\ncompelling addition to our comprehensive compensation and Total Rewards\\nbenefits* offerings. The annual allocation to the ESOP is fully funded by BDO\\nthrough investments in company stock and grants employees the chance to grow\\ntheir wealth over time as their shares vest and grow in value with the firmʼs\\nsuccess, with no employee contributions.\\nWe Are Committed To Delivering Exceptional Experiences To Middle Market\\nLeaders By Sharing Insight-driven Perspectives, Helping Companies Take\\nBusiness As Usual To Better Than Usual. With Industry Knowledge And\\nExperience, a Breadth And Depth Of Resources, And Unwavering Commitment To\\nQuality, We Pride Ourselves On\\nWelcoming diverse perspectives and understanding the experience of our\\nprofessionals and clients\\nEmpowering team members to explore their full potential\\nOur talented team who brings varying skills, knowledge and experience to\\nproactively help our clients navigate an expanding array of complex\\nchallenges and opportunities\\nCelebrating ingenuity and innovation to transform our business and help\\nour clients transform theirs\\nFocus on resilience and sustainability to positively impact our people,\\nclients, and communities\\nBenefits may be subject to eligibility requirements.\\nEqual Opportunity Employer, including disability/vets\\nClick here to find out more!\\nAll qualified applicants will receive consideration for employment without regard\\nto race, color, religion, sex, national origin, disability or protected veteran status.\\n\"BDO USA, P.A. is an EO employer M/F/Veteran/Disability\"\\nSet alert for similar jobs\\nMachine Learning Engineer, Columbia, MDSet alert\\nDetails found in the job post\\nRetrieved from the description\\nDeveloper Role\\nMachine Learning, DevOps, Embedded & Firmware, Data Engineering,\\nGame\\nTechnology\\nPython, Scala, GitHub, C, NET Framework, AWS, C++, Java, Azure, SQL\\nPay found in job post\\nRetrieved from the description.\\nBase salary\\n$100,000/yr - $155,000/yr (from job description)4/24/24, 1:54 PM (28) AI & ML Engineer | BDO USA | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3866911336/?eBP=CwEAAAGPET5Ue5oWGLmsFkyeWdZDoeYDvLIc3hupUJ92igPK7glibsZwKciq-ZSSXOWN7Wn7IeE24… 4/9', metadata={'source': 'data/Other/LinkedIn- AI & ML Engineer _ BDO USA _ LinkedIn.pdf', 'page': 3}),\n",
       " Document(page_content=\"Qualifications\\n4 skills match your profile. Stand out by adding other skills you\\nhave.\\nSkills associated with the job post\\nIdentified by LinkedIn\\n4 skills on your profile\\nArtificial Intelligence (AI), Data Modeling, Data Science, and Pattern Recogni…\\n6 skills missing on your profile\\nAWS SageMaker, Custom Integration, DDL, Data Manipulation, Star Schema,…\\nAdditional skills among applicants\\n8 skills other applicants have\\nData Analysis, Deep Learning, Machine Learning, PyTorch, Python (Program…\\nShow qualification details\\nPut your best foot forward with your application\\nHire a resume writer\\nGet a resume review\\nSee how you compare to other applicants\\nApplicants for this job\\n28Applicants\\n1Applicant in the past day\\nApplicant seniority level\\n13 Entry level applicants\\n3 Senior level applicants\\nApplicant education level\\n19%have a Doctor of Philosophy (Similar to you)\\n70%have a Master's Degree\\n11%have a Bachelor's Degree\\nApplicants are in these locations4/24/24, 1:54 PM (28) AI & ML Engineer | BDO USA | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3866911336/?eBP=CwEAAAGPET5Ue5oWGLmsFkyeWdZDoeYDvLIc3hupUJ92igPK7glibsZwKciq-ZSSXOWN7Wn7IeE24… 5/9\", metadata={'source': 'data/Other/LinkedIn- AI & ML Engineer _ BDO USA _ LinkedIn.pdf', 'page': 4}),\n",
       " Document(page_content='10-15 applicants\\nWashington DC-Baltimore\\nArea\\n1-5 applicants\\nSan Francisco Bay Area\\n1-5 applicants\\nUnited States\\nSee if BDO USA is hiring people like you\\nShow more Premium insightsThe latest hiring trends.\\n10,371\\nTotal employees0%\\nCompany-wide\\n2 year growth12%\\nFinance\\n2 year growth\\nMedian employee tenure ‧4 yearsApr 2022 Oct 2022 Apr 2023 Oct 2023 Apr 20245,00010,00015,000\\nBDO USA hires candidates from some of these companies and schools\\nBDO USA hired 1 person from Flatiron School.See all\\nFinance hires at BDO USA came from\\nthese companies and more.\\nSee more companiesFinance hires at BDO USA came from\\nthese schools and more.\\nSee more schools\\nAbout the company\\nBDO USA\\n147,714 followersFollow\\nAccounting•10,001+ employees•10,371 on LinkedIn\\nReset map4/24/24, 1:54 PM (28) AI & ML Engineer | BDO USA | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3866911336/?eBP=CwEAAAGPET5Ue5oWGLmsFkyeWdZDoeYDvLIc3hupUJ92igPK7glibsZwKciq-ZSSXOWN7Wn7IeE24… 6/9', metadata={'source': 'data/Other/LinkedIn- AI & ML Engineer _ BDO USA _ LinkedIn.pdf', 'page': 5}),\n",
       " Document(page_content='More jobsCommitments\\nWork-life balance\\nDiversity, equity, and inclusion\\nCareer growth and learning\\nEnvironmental sustainability\\nSocial impact\\nLearn more\\nCompany photos\\nShow moreThe measure of our success is in what we achieve together.\\nAt BDO, culture is the first order of business. We succeed when we cultivate a\\nconscious and caring corporate culture that puts people at the center of……show more\\nAs the needs of our people and clients have evolved, so has our flexible……Show more\\nDiversity, equity, and inclusion at BDO starts the way everything at BDO starts ……Show more\\nAt BDO, you can do much more than fulfill your career ambitions — you can……Show more\\nFor us, sustainability isnʼt about checking boxes. Itʼs about taking steps to……Show more\\nOur core purpose is helping people thrive, every day. At BDO, we believe that ou……Show more\\nInterested in working with us in the future?\\nPrivately share your profile with our recruiters – youʼll be noted as\\nexpressing interest for up to a year.Learn more\\nIʼm interested\\nMachine Learning\\nEngineer\\nElsdon Consulting ltd\\nColumbia, MD (On-site)\\nActively recruiting\\n6 days agoEasy ApplyMachine Learning\\nEngineer\\nRAND\\nWashington DC-Baltimore Area\\n(On-site)\\n1 week ago\\n4/24/24, 1:54 PM (28) AI & ML Engineer | BDO USA | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3866911336/?eBP=CwEAAAGPET5Ue5oWGLmsFkyeWdZDoeYDvLIc3hupUJ92igPK7glibsZwKciq-ZSSXOWN7Wn7IeE24… 7/9', metadata={'source': 'data/Other/LinkedIn- AI & ML Engineer _ BDO USA _ LinkedIn.pdf', 'page': 6}),\n",
       " Document(page_content='See more jobs like thisSoftware and AI\\nIntegration Engineer\\nBooz Allen Hamilton\\nHonolulu, HI (Hybrid)\\n2 connections work here\\n3 weeks agoSoftware Engineer /\\nResearch Scientist\\nParsons Corporation\\nAberdeen, MD (On-site)\\nActively recruiting\\n6 days ago16 applicants\\nMachine Learning\\nEngineer / AI Engineer\\nDice\\nMinneapolis, MN (On-site)\\n2 hours agoAI Software Developer\\nIBM\\nYorktown Heights, NY\\n3 company alumni work here\\n2 weeks ago\\nMachine Learning\\nEngineer\\nRAND\\nPittsburgh, PA (On-site)\\n1 week agoSoftware Engineer-\\nRemote\\nJacobs\\nHanover, MD\\n1 company alum works here\\n1 week ago\\nData Engineer (Jr/Mid)\\nCGI\\nBaltimore, MD\\nActively recruiting\\n1 month agoSoftware Engineer\\nBoeing\\nAnnapolis Junction, MD\\n6 company alumni work here\\n2 weeks ago\\nSystems Engineer\\nThe Johns Hopkins University\\nBaltimore, MD (Hybrid)\\n2 connections work here\\n3 weeks agoJunior AI/ML Software\\nEngineer\\nDice\\nWashington, VA (On-site)\\n2 hours ago4/24/24, 1:54 PM (28) AI & ML Engineer | BDO USA | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3866911336/?eBP=CwEAAAGPET5Ue5oWGLmsFkyeWdZDoeYDvLIc3hupUJ92igPK7glibsZwKciq-ZSSXOWN7Wn7IeE24… 8/9', metadata={'source': 'data/Other/LinkedIn- AI & ML Engineer _ BDO USA _ LinkedIn.pdf', 'page': 7}),\n",
       " Document(page_content='About Accessibility Talent Solutions\\nCommunity Guidelines Careers Marketing Solutions\\nAd Choices Advertising\\nSales Solutions Mobile Small Business\\nSafety CenterQuestions?\\nVisit our Help Center.\\nManage your account and privacy\\nGo to your Settings.\\nRecommendation transparency\\nLearn more about Recommended Content.Select Language\\nLinkedIn Corporation © 2024Learn skills to get a new job with these courses\\n20,722 viewers\\n1,890 viewers\\nShow more on LinkedIn Learning\\nETL in Python and SQL\\nLearning Azure Stream Analytics\\nEssentials of MLOps with Azure: 2 Databricks MLflow and MLflow\\nTracking\\nLooking for talent?Post a job\\nPrivacy & Terms\\nEnglish (English)4/24/24, 1:54 PM (28) AI & ML Engineer | BDO USA | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3866911336/?eBP=CwEAAAGPET5Ue5oWGLmsFkyeWdZDoeYDvLIc3hupUJ92igPK7glibsZwKciq-ZSSXOWN7Wn7IeE24… 9/9', metadata={'source': 'data/Other/LinkedIn- AI & ML Engineer _ BDO USA _ LinkedIn.pdf', 'page': 8})]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from langchain_community.document_loaders.pdf import PyPDFLoader, PyPDFParser\n",
    "\n",
    "loader = PyPDFLoader(\n",
    "    file_path = test_pdf,#\"./example_data/layout-parser-paper.pdf\",\n",
    "    # password = \"my-pasword\",\n",
    "    # extract_images = True,\n",
    "    # headers = None\n",
    "    # extraction_mode = \"plain\",\n",
    "    # extraction_kwargs = None,\n",
    ")\n",
    "\n",
    "pdf_docs = loader.load()\n",
    "pdf_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'data/Other/LinkedIn- AI & ML Engineer _ BDO USA _ LinkedIn.pdf',\n",
       " 'page': 0}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_docs[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PDF gets split into separate pages by default.\n",
    "- If from LinkedIn, may contain Premium Membership insights at bottom (which we don't want)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents.base import Document\n",
    "def load_join_annotate_pdf(pdf_fpath, metadata = {}):\n",
    "    \"\"\"\n",
    "    Loads a PDF file, joins its content, and annotates it with metadata.\n",
    "    Args:\n",
    "        pdf_fpath (str): The file path to the PDF document.\n",
    "        metadata (dict, optional): Additional metadata to annotate the document. Defaults to an empty dictionary.\n",
    "    Returns:\n",
    "        Document: A Document object containing the concatenated text of the PDF and the provided metadata.\n",
    "    \"\"\"\n",
    "    loader = PyPDFLoader(file_path = pdf_fpath)\n",
    "    pdf_docs = loader.load()\n",
    "    pdf_text = \" \".join([doc.page_content for doc in pdf_docs])\n",
    "    \n",
    "    # Return to later for cleaning up stored docs\n",
    "    # split_text = pdf_text.split(\"Premium\")\n",
    "    # pdf_text = split_text[0]\n",
    "    return Document(page_content = pdf_text,\n",
    "                    metadata = {'file_path': pdf_fpath,\n",
    "                                **metadata})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary map of the sources to trust_rank\n",
    "source_rank_map = {'manual':1 , 'applyall':2, 'scraped':3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " BDO USA | LinkedIn\n",
      "https://www.linkedin.com/jobs/view/3866911336/?eBP=CwEAAAGPET5Ue5oWGLmsFkyeWdZDoeYDvLIc3hupUJ92igPK7glibsZwKciq-ZSSXOWN7Wn7IeE24… 8/9 About Accessibility Talent Solutions\n",
      "Community Guidelines Careers Marketing Solutions\n",
      "Ad Choices Advertising\n",
      "Sales Solutions Mobile Small Business\n",
      "Safety CenterQuestions?\n",
      "Visit our Help Center.\n",
      "Manage your account and privacy\n",
      "Go to your Settings.\n",
      "Recommendation transparency\n",
      "Learn more about Recommended Content.Select Language\n",
      "LinkedIn Corporation © 2024Learn skills to get a new job with these courses\n",
      "20,722 viewers\n",
      "1,890 viewers\n",
      "Show more on LinkedIn Learning\n",
      "ETL in Python and SQL\n",
      "Learning Azure Stream Analytics\n",
      "Essentials of MLOps with Azure: 2 Databricks MLflow and MLflow\n",
      "Tracking\n",
      "Looking for talent?Post a job\n",
      "Privacy & Terms\n",
      "English (English)4/24/24, 1:54 PM (28) AI & ML Engineer | BDO USA | LinkedIn\n",
      "https://www.linkedin.com/jobs/view/3866911336/?eBP=CwEAAAGPET5Ue5oWGLmsFkyeWdZDoeYDvLIc3hupUJ92igPK7glibsZwKciq-ZSSXOWN7Wn7IeE24… 9/9\n",
      "{'file_path': 'data/Other/LinkedIn- AI & ML Engineer _ BDO USA _ LinkedIn.pdf', 'file_name': 'LinkedIn- AI & ML Engineer _ BDO USA _ LinkedIn.pdf', 'source': 'manual', 'trust_rank': 1}\n"
     ]
    }
   ],
   "source": [
    "# Set the metadata for the document\n",
    "meta_data = {'file_path': test_pdf, 'file_name': os.path.basename(test_pdf),\n",
    "             'source':'manual'}\n",
    "meta_data['trust_rank']=source_rank_map['manual']\n",
    "\n",
    "# Load, join and annotate the pdf\n",
    "doc = load_join_annotate_pdf(test_pdf, metadata=meta_data)\n",
    "print(doc.page_content[-1000:])\n",
    "print(doc.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36e79672f45f43dcaf317b2e580cb379",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading manual pdfs:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1c9ffd0817840148d5c5f5ddc728673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading applyall pdfs:   0%|          | 0/260 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# List to store all documents\n",
    "documents =  []\n",
    "\n",
    "# Loop to load all manual pdfs\n",
    "\n",
    "for fpath in tqdm(manual_pds,desc='Loading manual pdfs'):\n",
    "    meta_data = {'file_path': fpath, 'file_name': os.path.basename(fpath),\n",
    "                 'source':'manual'}\n",
    "    meta_data['trust_rank']=source_rank_map['manual']\n",
    "    doc = load_join_annotate_pdf(fpath, metadata=meta_data)\n",
    "    documents.append(doc)\n",
    "    \n",
    "for fpath in tqdm(applyall_pds,desc='Loading applyall pdfs'):\n",
    "    meta_data = {'file_path': fpath, 'file_name': os.path.basename(fpath),\n",
    "                 'source':'applyall'}\n",
    "    meta_data['trust_rank']=source_rank_map['applyall']\n",
    "    doc = load_join_annotate_pdf(fpath, metadata=meta_data)\n",
    "    documents.append(doc)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "268"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "for fpath in tqdm(applyall_pds, desc='Loading applyall pdfs'):\n",
    "    meta_data = {'file_path': fpath, 'file_name': os.path.basename(fpath),\n",
    "                 'source':'applyall'}\n",
    "    meta_data['trust_rank']=source_rank_map['applyall']\n",
    "    doc = load_join_annotate_pdf(fpath, metadata=meta_data)\n",
    "    documents.append(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Database Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (0.7.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/codingdojo/.local/lib/python3.10/site-packages (from tiktoken) (2023.12.25)\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2024.7.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Encoding 'o200k_base'>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check # of tokens per document\n",
    "# adapted from: https://github.com/openai/tiktoken/blob/main/README.md\n",
    "import tiktoken\n",
    "# To get the tokeniser corresponding to a specific model in the OpenAI API:\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4o\")\n",
    "encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1563"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# enc.encode(\"Hello, world!\")\n",
    "tokens = encoding.encode(documents[0].page_content)\n",
    "num_tokens = len(tokens)\n",
    "num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_num_tiktokens(doc, model_name=\"gpt-4o\"):\n",
    "    \"\"\"\n",
    "    Returns the number of tokens per document.\n",
    "    Args:\n",
    "        documents (list): A list of Document objects.\n",
    "    Returns:\n",
    "        list: A list of integers representing the number of tokens per document.\n",
    "    \"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(model_name)\n",
    "    tokens = encoding.encode(doc.page_content)\n",
    "    return len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1563"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_tokens = calc_num_tiktokens(documents[0])\n",
    "n_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97cbce9cee634ced88c7403278e443f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating tokens:   0%|          | 0/268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_tokens = []\n",
    "\n",
    "for doc in tqdm(documents, desc='Calculating tokens'):\n",
    "    n_tokens = calc_num_tiktokens(doc)\n",
    "    num_tokens.append(n_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize the distribution of tokens\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "ax= sns.histplot(num_tokens)\n",
    "fig = ax.get_figure()\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_text_splitters.character.RecursiveCharacterTextSplitter at 0x176d261a0>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Switch to Recursive Character Text Splitter\n",
    "# text_splitter = CharacterTextSplitter.from_tiktoken_encoder(chunk_size=500,chunk_overlap=100)\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=1000,chunk_overlap=100)\n",
    "text_splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ## Calculating price https://openai.com/api/pricing/\n",
    "# pricing = [['Model','Token Type','Price per 1000 tokens']]\n",
    "# pricing.append(['gpt-4o','input tokens', 0.000250])\n",
    "# pricing.append(['gpt-4o','output tokens', 0.01])\n",
    "# pricing.append(['gpt-4o-mini','input tokens', 0.000150])\n",
    "# pricing.append(['gpt-4o-mini','output tokens', 0.0000600])\n",
    "# price_df = pd.DataFrame(pricing[1:], columns=pricing[0])\n",
    "# price_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input Price per 1000 tokens</th>\n",
       "      <th>Output Price per 1000 tokens</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gpt-4o</th>\n",
       "      <td>0.00025</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4o-mini</th>\n",
       "      <td>0.00015</td>\n",
       "      <td>0.00006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text-embedding-3-small</th>\n",
       "      <td>0.00002</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text-embedding-ada-002</th>\n",
       "      <td>0.00010</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Input Price per 1000 tokens  \\\n",
       "Model                                                 \n",
       "gpt-4o                                      0.00025   \n",
       "gpt-4o-mini                                 0.00015   \n",
       "text-embedding-3-small                      0.00002   \n",
       "text-embedding-ada-002                      0.00010   \n",
       "\n",
       "                       Output Price per 1000 tokens  \n",
       "Model                                                \n",
       "gpt-4o                                         0.01  \n",
       "gpt-4o-mini                                 0.00006  \n",
       "text-embedding-3-small                         <NA>  \n",
       "text-embedding-ada-002                         <NA>  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ## Calculating price https://openai.com/api/pricing/\n",
    "pricing = [['Model','Input Price per 1000 tokens', 'Output Price per 1000 tokens']]\n",
    "pricing.append(['gpt-4o', 0.000250, 0.01])\n",
    "pricing.append(['gpt-4o-mini', 0.000150, 0.0000600])\n",
    "pricing.append(['text-embedding-3-small',0.000020,pd.NA])\n",
    "pricing.append(['text-embedding-ada-002',0.000100,pd.NA])\n",
    "price_df = pd.DataFrame(pricing[1:], columns=pricing[0])\n",
    "price_df = price_df.set_index('Model')\n",
    "price_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_a36e0_row0_col0 {\n",
       "  background-color: #023858;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a36e0_row1_col0 {\n",
       "  background-color: #549cc7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a36e0_row2_col0 {\n",
       "  background-color: #fff7fb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a36e0_row3_col0 {\n",
       "  background-color: #afc1dd;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a36e0\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_a36e0_level0_col0\" class=\"col_heading level0 col0\" >Input Price per 1000 tokens</th>\n",
       "      <th id=\"T_a36e0_level0_col1\" class=\"col_heading level0 col1\" >Output Price per 1000 tokens</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Model</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a36e0_level0_row0\" class=\"row_heading level0 row0\" >gpt-4o</th>\n",
       "      <td id=\"T_a36e0_row0_col0\" class=\"data row0 col0\" >0.000250</td>\n",
       "      <td id=\"T_a36e0_row0_col1\" class=\"data row0 col1\" >0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a36e0_level0_row1\" class=\"row_heading level0 row1\" >gpt-4o-mini</th>\n",
       "      <td id=\"T_a36e0_row1_col0\" class=\"data row1 col0\" >0.000150</td>\n",
       "      <td id=\"T_a36e0_row1_col1\" class=\"data row1 col1\" >0.000060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a36e0_level0_row2\" class=\"row_heading level0 row2\" >text-embedding-3-small</th>\n",
       "      <td id=\"T_a36e0_row2_col0\" class=\"data row2 col0\" >0.000020</td>\n",
       "      <td id=\"T_a36e0_row2_col1\" class=\"data row2 col1\" ><NA></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a36e0_level0_row3\" class=\"row_heading level0 row3\" >text-embedding-ada-002</th>\n",
       "      <td id=\"T_a36e0_row3_col0\" class=\"data row3 col0\" >0.000100</td>\n",
       "      <td id=\"T_a36e0_row3_col1\" class=\"data row3 col1\" ><NA></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x31a7d7850>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_df.style.background_gradient(subset=['Input Price per 1000 tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "296270"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the total number of tokens\n",
    "total_tokens = np.sum(num_tokens)\n",
    "total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "296.27"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the total number of tokens in thousands\n",
    "thousands_of_tokens = total_tokens/ 1000\n",
    "thousands_of_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0059254"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the cost of encoding the documents with text-embedding-3-small\n",
    "encoding_cost_3small = price_df.loc['text-embedding-3-small',\n",
    "                             'Input Price per 1000 tokens']\\\n",
    "                            * thousands_of_tokens\n",
    "encoding_cost_3small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.029627"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the cost of encoding the documents with text-embedding-ada-002\n",
    "encoding_cost_ada = price_df.loc['text-embedding-ada-002',\n",
    "                                'Input Price per 1000 tokens']\\\n",
    "                                * thousands_of_tokens\n",
    "encoding_cost_ada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenAIEmbeddings(client=<openai.resources.embeddings.Embeddings object at 0x31a7d6bf0>, async_client=<openai.resources.embeddings.AsyncEmbeddings object at 0x31d2c8760>, model='text-embedding-3-small', dimensions=None, deployment='text-embedding-ada-002', openai_api_version='', openai_api_base=None, openai_api_type='', openai_proxy='', embedding_ctx_length=8191, openai_api_key=SecretStr('**********'), openai_organization=None, allowed_special=set(), disallowed_special='all', chunk_size=1000, max_retries=2, request_timeout=None, headers=None, tiktoken_enabled=True, tiktoken_model_name=None, show_progress_bar=False, model_kwargs={}, skip_empty=False, default_headers=None, default_query=None, retry_min_seconds=4, retry_max_seconds=20, http_client=None, http_async_client=None)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create embedding function with cheapest model\n",
    "embedding_func = OpenAIEmbeddings(model='text-embedding-3-small')\n",
    "embedding_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "463"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Embed the documents\n",
    "split_docs = text_splitter.split_documents(documents)\n",
    "len(split_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Chroma vector store\n",
    "db = Chroma.from_documents(split_docs, embedding_func, persist_directory= \"data/Chroma\")\n",
    "# Use persist to save to disk\n",
    "db.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='outputs to the task at hand.\\nMS  degree in\\xa0Statistics, Ma th,\\xa0Data Analytics, or a related quantitative ﬁeld\\xa0\\nAt\\xa0least 3\\xa0years of post graduate professi onal experience in Advanced Data Science, su ch as predictive modeling,\\nstatistical analysi s, machine learning, text mining, geosp atial analytics, time series forecasting, optimization\\xa0\\nDemonstrated Experience with NLP and other components of AI\\nExperience implementing AI so lutions\\nExperience with one or more\\xa0Advanced Data Science so ftware languages (Python,\\xa0R,\\xa0SAS)\\xa0\\xa0\\nProven ability to deploy\\xa0machine learning models from the research environment (Jupyter\\xa0Notebooks)\\xa0to\\xa0production\\nvia\\xa0procedural\\xa0or\\xa0pipeline\\xa0approaches\\xa0\\nExperience\\xa0with\\xa0SQL\\xa0and\\xa0relational databases, query authoring\\xa0and tuning\\xa0as well as working familiarity with a variety\\nof databases\\xa0including Hadoop/Hive\\xa0\\nExperience with sp ark and data-frames in\\xa0PyS park\\xa0or Scala\\xa0\\nStrong\\xa0problem-so lving skills; ability to pivo t complex data to answe r business questions. Proven ability to visu alize\\ndata for inﬂuencing.\\xa0\\nComfortable with cloud-based platforms (AWS, Azure, Google)\\xa0\\nExperience with Google Analytics, Adobe Analytics, Optimizely a plus\\xa0\\nPrivacy Policy Imprint\\nCookies Settings', metadata={'file_path': 'data/ApplyAll/Blend360 AI Data Scientist - Manager _ SmartRecruiters.pdf', 'file_name': 'Blend360 AI Data Scientist - Manager _ SmartRecruiters.pdf', 'source': 'applyall', 'trust_rank': 2})"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What skills are required for the role of a data scientist?\"\n",
    "found_docs = db.as_retriever(k=3).invoke(question)\n",
    "found_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_path': 'data/ApplyAll/Blend360 AI Data Scientist - Manager _ SmartRecruiters.pdf',\n",
       " 'file_name': 'Blend360 AI Data Scientist - Manager _ SmartRecruiters.pdf',\n",
       " 'source': 'applyall',\n",
       " 'trust_rank': 2}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "found_docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construbt metadata field AttributeInfo\n",
    "metadata_field_info = [\n",
    "    AttributeInfo(name='source',type='string',description='Category of source type. One of manual, applyall, or scraped'),\n",
    "    AttributeInfo(name='trust_rank',type='int',description='Rank of the source of the document. Lower is better.'),\n",
    "    AttributeInfo(name='file_name',type='string',description='Name of the file'),\n",
    "    AttributeInfo(name='file_path',type='string',description='Path to the file')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6860"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many tokens would be in k # of documents\n",
    "k = 8\n",
    "np.random.choice(num_tokens, k).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SelfQueryRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the self query retriever\n",
    "document_content_description = \"Job listings\"\n",
    "# llm = ChatOpenAI(temperature=0, model='gpt-4o-mini')\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    ChatOpenAI(temperature=0, model='gpt-4o-mini'),\n",
    "    db,\n",
    "    document_content_description,\n",
    "    metadata_field_info,\n",
    "    enable_limit=True,\n",
    "    search_kwargs = {'k':8}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MultiQueryRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiQueryRetriever(retriever=SelfQueryRetriever(vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x31adc12a0>, query_constructor=RunnableBinding(bound=FewShotPromptTemplate(input_variables=['query'], examples=[{'i': 1, 'data_source': '```json\\n{{\\n    \"content\": \"Lyrics of a song\",\\n    \"attributes\": {{\\n        \"artist\": {{\\n            \"type\": \"string\",\\n            \"description\": \"Name of the song artist\"\\n        }},\\n        \"length\": {{\\n            \"type\": \"integer\",\\n            \"description\": \"Length of the song in seconds\"\\n        }},\\n        \"genre\": {{\\n            \"type\": \"string\",\\n            \"description\": \"The song genre, one of \"pop\", \"rock\" or \"rap\"\"\\n        }}\\n    }}\\n}}\\n```', 'user_query': 'What are songs by Taylor Swift or Katy Perry about teenage romance under 3 minutes long in the dance pop genre', 'structured_request': '```json\\n{{\\n    \"query\": \"teenager love\",\\n    \"filter\": \"and(or(eq(\\\\\"artist\\\\\", \\\\\"Taylor Swift\\\\\"), eq(\\\\\"artist\\\\\", \\\\\"Katy Perry\\\\\")), lt(\\\\\"length\\\\\", 180), eq(\\\\\"genre\\\\\", \\\\\"pop\\\\\"))\"\\n}}\\n```'}, {'i': 2, 'data_source': '```json\\n{{\\n    \"content\": \"Lyrics of a song\",\\n    \"attributes\": {{\\n        \"artist\": {{\\n            \"type\": \"string\",\\n            \"description\": \"Name of the song artist\"\\n        }},\\n        \"length\": {{\\n            \"type\": \"integer\",\\n            \"description\": \"Length of the song in seconds\"\\n        }},\\n        \"genre\": {{\\n            \"type\": \"string\",\\n            \"description\": \"The song genre, one of \"pop\", \"rock\" or \"rap\"\"\\n        }}\\n    }}\\n}}\\n```', 'user_query': 'What are songs that were not published on Spotify', 'structured_request': '```json\\n{{\\n    \"query\": \"\",\\n    \"filter\": \"NO_FILTER\"\\n}}\\n```'}, {'i': 3, 'data_source': '```json\\n{{\\n    \"content\": \"Lyrics of a song\",\\n    \"attributes\": {{\\n        \"artist\": {{\\n            \"type\": \"string\",\\n            \"description\": \"Name of the song artist\"\\n        }},\\n        \"length\": {{\\n            \"type\": \"integer\",\\n            \"description\": \"Length of the song in seconds\"\\n        }},\\n        \"genre\": {{\\n            \"type\": \"string\",\\n            \"description\": \"The song genre, one of \"pop\", \"rock\" or \"rap\"\"\\n        }}\\n    }}\\n}}\\n```', 'user_query': 'What are three songs about love', 'structured_request': '```json\\n{{\\n    \"query\": \"love\",\\n    \"filter\": \"NO_FILTER\",\\n    \"limit\": 2\\n}}\\n```'}], example_prompt=PromptTemplate(input_variables=['data_source', 'i', 'structured_request', 'user_query'], template='<< Example {i}. >>\\nData Source:\\n{data_source}\\n\\nUser Query:\\n{user_query}\\n\\nStructured Request:\\n{structured_request}\\n'), suffix='<< Example 4. >>\\nData Source:\\n```json\\n{{\\n    \"content\": \"Job listings\",\\n    \"attributes\": {{\\n    \"source\": {{\\n        \"description\": \"Category of source type. One of manual, applyall, or scraped\",\\n        \"type\": \"string\"\\n    }},\\n    \"trust_rank\": {{\\n        \"description\": \"Rank of the source of the document. Lower is better.\",\\n        \"type\": \"int\"\\n    }},\\n    \"file_name\": {{\\n        \"description\": \"Name of the file\",\\n        \"type\": \"string\"\\n    }},\\n    \"file_path\": {{\\n        \"description\": \"Path to the file\",\\n        \"type\": \"string\"\\n    }}\\n}}\\n}}\\n```\\n\\nUser Query:\\n{query}\\n\\nStructured Request:\\n', prefix='Your goal is to structure the user\\'s query to match the request schema provided below.\\n\\n<< Structured Request Schema >>\\nWhen responding use a markdown code snippet with a JSON object formatted in the following schema:\\n\\n```json\\n{{\\n    \"query\": string \\\\ text string to compare to document contents\\n    \"filter\": string \\\\ logical condition statement for filtering documents\\n    \"limit\": int \\\\ the number of documents to retrieve\\n}}\\n```\\n\\nThe query string should contain only text that is expected to match the contents of documents. Any conditions in the filter should not be mentioned in the query as well.\\n\\nA logical condition statement is composed of one or more comparison and logical operation statements.\\n\\nA comparison statement takes the form: `comp(attr, val)`:\\n- `comp` (eq | ne | gt | gte | lt | lte): comparator\\n- `attr` (string):  name of attribute to apply the comparison to\\n- `val` (string): is the comparison value\\n\\nA logical operation statement takes the form `op(statement1, statement2, ...)`:\\n- `op` (and | or): logical operator\\n- `statement1`, `statement2`, ... (comparison statements or logical operation statements): one or more statements to apply the operation to\\n\\nMake sure that you only use the comparators and logical operators listed above and no others.\\nMake sure that filters only refer to attributes that exist in the data source.\\nMake sure that filters only use the attributed names with its function names if there are functions applied on them.\\nMake sure that filters only use format `YYYY-MM-DD` when handling date data typed values.\\nMake sure that filters take into account the descriptions of attributes and only make comparisons that are feasible given the type of data being stored.\\nMake sure that filters are only used as needed. If there are no filters that should be applied return \"NO_FILTER\" for the filter value.\\nMake sure the `limit` is always an int value. It is an optional parameter so leave it blank if it does not make sense.\\n')\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x329ca3340>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x329ca16f0>, model_name='gpt-4o-mini', temperature=0.0, openai_api_key=SecretStr('**********'), openai_proxy='')\n",
       "| StructuredQueryOutputParser(ast_parse=<bound method Lark.parse of Lark(open('<string>'), parser='lalr', lexer='contextual', ...)>), config={'run_name': 'query_constructor'}), search_kwargs={'k': 8}, structured_query_translator=<langchain.retrievers.self_query.chroma.ChromaTranslator object at 0x329ca19c0>), llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['question'], template='You are an AI language model assistant. Your task is to generate five \\n    different versions of the given user question to retrieve relevant documents from a vector \\n    database. By generating multiple perspectives on the user question, your goal is to help\\n    the user overcome some of the limitations of the distance-based similarity search. \\n    Provide these alternative questions separated by newlines.\\n    Original question: {question}'), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x32021c6a0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x3253711b0>, model_name='gpt-4o-mini', temperature=0.0, openai_api_key=SecretStr('**********'), openai_proxy=''), output_parser=LineListOutputParser()))"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain.prompts import PromptTemplate\n",
    "# Set logging for the queries\n",
    "import logging\n",
    "\n",
    "logging.basicConfig()\n",
    "logging.getLogger(\"langchain.retrievers.multi_query\").setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "QUERY_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"\"\"You are an AI language model assistant. Your task is to generate five \n",
    "    different versions of the given user question to retrieve relevant documents from a vector \n",
    "    database. By generating multiple perspectives on the user question, your goal is to help\n",
    "    the user overcome some of the limitations of the distance-based similarity search. \n",
    "    Provide these alternative questions separated by newlines.\n",
    "    Original question: {question}\"\"\",\n",
    ")\n",
    "\n",
    "llm_query = ChatOpenAI(temperature=0, model='gpt-4o-mini')\n",
    "\n",
    "# Run\n",
    "retriever_multi = MultiQueryRetriever.from_llm(retriever=retriever, llm=llm_query, prompt=QUERY_PROMPT)\n",
    "retriever_multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain.retrievers.multi_query:Generated queries: ['What are the essential skills needed to become a data scientist?  ', 'Can you list the key competencies for a data scientist position?  ', 'What abilities should one possess to work effectively as a data scientist?  ', 'What qualifications and skills are important for a career in data science?  ', 'Which technical and soft skills are crucial for data scientists?']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(page_content='outputs to the task at hand.\\nMS  degree in\\xa0Statistics, Ma th,\\xa0Data Analytics, or a related quantitative ﬁeld\\xa0\\nAt\\xa0least 3\\xa0years of post graduate professi onal experience in Advanced Data Science, su ch as predictive modeling,\\nstatistical analysi s, machine learning, text mining, geosp atial analytics, time series forecasting, optimization\\xa0\\nDemonstrated Experience with NLP and other components of AI\\nExperience implementing AI so lutions\\nExperience with one or more\\xa0Advanced Data Science so ftware languages (Python,\\xa0R,\\xa0SAS)\\xa0\\xa0\\nProven ability to deploy\\xa0machine learning models from the research environment (Jupyter\\xa0Notebooks)\\xa0to\\xa0production\\nvia\\xa0procedural\\xa0or\\xa0pipeline\\xa0approaches\\xa0\\nExperience\\xa0with\\xa0SQL\\xa0and\\xa0relational databases, query authoring\\xa0and tuning\\xa0as well as working familiarity with a variety\\nof databases\\xa0including Hadoop/Hive\\xa0\\nExperience with sp ark and data-frames in\\xa0PyS park\\xa0or Scala\\xa0\\nStrong\\xa0problem-so lving skills; ability to pivo t complex data to answe r business questions. Proven ability to visu alize\\ndata for inﬂuencing.\\xa0\\nComfortable with cloud-based platforms (AWS, Azure, Google)\\xa0\\nExperience with Google Analytics, Adobe Analytics, Optimizely a plus\\xa0\\nPrivacy Policy Imprint\\nCookies Settings', metadata={'file_path': 'data/ApplyAll/Blend360 AI Data Scientist - Manager _ SmartRecruiters.pdf', 'file_name': 'Blend360 AI Data Scientist - Manager _ SmartRecruiters.pdf', 'source': 'applyall', 'trust_rank': 2}),\n",
       " Document(page_content=\"Data Scientist\\nArlington, Virginia, United States, Remote\\nExcella is a leading provider of Agile software development and data and analytics solutions to clients in the\\nfederal, commercial and non-proﬁt sectors. W e believe that great work leads to great\\xa0things –- our experts\\nmeasure success by the positive impact we make on our clients, community , and colleagues. W e are growing\\nfast and need passionate, innovative people who love working with technology and are ready to make an impact.\\nHere's what you can expect from us:\\nWorkplace sites look dif ferent for everyone – whether it’ s your home or the ofﬁce, we believe in a ﬂexible\\nwork/life balance that supports you regardless of your location. W e offer a home ofﬁce allowance that can\\nbe used for home ofﬁce\\xa0furniture/equipment, a daily\\xa0pass for a coworking space, etc. Our commute\\nreimbursement plan has you covered for whether you bike, Metro, or drive to work.\\nWe offer top of industry medical, dental, and vision beneﬁts with multiple options to choose from such as an\\nemployer-contributed health savings account, infertility coverage, and orthodontia so you can select the\\nplan that works best for you.\\nRegardless of what stage of life you’re in, Excella wants to support you. W e provide 8 weeks of Parental\\nLeave, discounted pet insurance, and a Care.com membership with 3 back-up emergency child or elder\\ncare days annually – all available to you on your ﬁrst day .\\nStarting day one, every employee is bonus eligible and receives 15 days of paid vacation, 6 federal\\nholidays, and 4 ﬂoating holidays.\\nDoing your best work means having the best tools! Excella’ s TechEleX program provides you with multiple\\noptions to suit your technology needs. Choose between a variety of Mac or PC devices, and to ensure your\\nhardware remains current, at the end of a 3-year period Excella will replace your existing computer with a\\nnew model from the program. Plus, we’ll even give you the original device to keep for your personal use!\\nExcella provides a W orkplace Allowance to of fset both the costs to maintain a distributed work environment\\nand to enhance your workplace wellness. Excella will reimburse all full-time Excellians for up to $500 in\\nexpenses incurred during the calendar year .\\nDiversity and inclusion matter . Excella created and continues to support employee led-afﬁnity groups and\\nthe Inclusion Diversity Equity Ambassador (IDEA) team, a cross-functional employee-led initiative to\\ncontinually foster innovation and increase inclusion within Excella.\\nWe'll invest in your career by providing 3 days of paid professional development every year , including travel\\nand registration fees to attend classes and conferences.\\nWe encourage mindfulness and overall well-being through employee wellness events, a HeadSpace\\nmembership, as well as access to TalkSpace and mental health coverage through our medical plans.\\nOverview\\nThe Data Scientist is responsible for using advanced statistical, algorithmic, machine learning, data mining and\\nvisualization techniques to help advance and complete client projects. The Data Scientist must also be able to\\ncommunicate complex quantitative analyses in a clear , precise, and actionable manner to management and\\nexecutive level audiences.\\nResponsibilities\\nWorking directly with client stakeholders to understand and deﬁne analysis objectives and then translate\\nthese into actionable results. Obtaining data from multiple, disparate data sources including structured, semi-structured and unstructured\\ndata.\\nUsing machine learning and data mining technique to understand the patterns in large volumes of data,\\nidentify relationships detect data anomalies, and classify data sets.\\nWorking with data integration developers to assess data quality and deﬁne data processing business rules\\nfor cleansing, aggregation, enhancement etc. support analysis and predictive modeling activities.\\nDesigning and building algorithms and predictive models using techniques such as linear and logistic\\nregression, support vector machines, ensemble models (random forest and/or gradient boosted trees),\\nneural networks, and clustering techniques.\\nDeploying predictive models and integrating them into business processes and applications.\\nValidating and optimizing model performance upon deployment and tracking over time as necessary .\\nPresenting complex analysis results tailored to dif ferent audiences (e.g. technical, manager , executive) in a\\nhighly consumable and actionable form including the use of data visualizations.\\nQualiﬁcations\\nT echnical:\", metadata={'file_path': 'data/ApplyAll/Job Application for Data Scientist at Excella.pdf', 'file_name': 'Job Application for Data Scientist at Excella.pdf', 'source': 'applyall', 'trust_rank': 2}),\n",
       " Document(page_content='opportunities to apply new techniques to our e-commerce challenges.\\nQualiﬁcations\\nExperience: \\xa05+ years of hands-on experience in data science, machine learning, or a related role.\\nTechnical Skills:\\nProﬁciency in Python and SQL.\\nExperience with machine learning frameworks and libraries (e.g., TensorFlow , PyT orch, Scikit-learn).\\nStrong understanding of statistical methods and data analysis techniques.\\nFamiliarity with data manipulation and analysis tools (e.g., pandas, NumPy).\\nExperience with data visualization frameworks and tools (e.g., Matplotlib, Seaborn) is a plus.\\nAnalytical Mindset: \\xa0Strong problem-solving skills with the ability to translate complex data into actionable\\ninsights.\\nCommunication: \\xa0Excellent written and verbal communication skills, with the ability to explain technical\\nconcepts to non-technical stakeholders.\\nTeam Player: \\xa0Collaborative spirit with a proactive attitude and the ability to work independently when\\nrequired.\\nWe are an equal opportunity employer/minority/female/disability/protected veteran.', metadata={'file_path': 'data/ApplyAll/Job Application for Data Scientist at 1848 Ventures.pdf', 'file_name': 'Job Application for Data Scientist at 1848 Ventures.pdf', 'source': 'applyall', 'trust_rank': 2}),\n",
       " Document(page_content='Data Scientist\\nSan Jose, CA, USA, San Jose, CA\\nFull-time\\nCompany Description\\nWe are seeking a data scientist with at least 1 year of experience working with large data sets and 10 years of total\\nprofessi onal experience. This role is expected to translate business objectives into actionable data analysi s and\\ncommunicate ﬁndings clearly to technical and non-technical audiences\\nJob Description\\nRequired\\n• Analytical thinking;\\n• Understanding of statistics fundamentals;\\n• In-depth knowledge on the Hadoop stack (Ma p reduce, HDFS, Hive, Pig);\\n• In-depth knowledge on machine learning methods;\\n• Experience with scripting languages su ch as Python;\\n• Understanding of main statistical methods;\\n• Understanding of sampling techniques;\\n• Understanding of descriptive and inferential statistics concepts;\\n• Business domain experience in one of the following areas: retail, enterprise mobility, healthcare;\\nQualiﬁcations\\n• B.Sc. degree in Computer Science, Engineering, Ma thematics, Statistics or related ﬁeld is required\\n• M. Sc. / Ph.D degree in related ﬁeld is desirable.\\nAdditional Information\\nAll yo ur information will be kept conﬁdential according to EEO guidelines. Job Location\\nCookies Settings\\nPowered by\\n\\xa0(Data Processor)\\nPrivacy Policy\\xa0and\\xa0Terms of Use', metadata={'file_path': 'data/ApplyAll/Samsung Data Scientist _ SmartRecruiters.pdf', 'file_name': 'Samsung Data Scientist _ SmartRecruiters.pdf', 'source': 'applyall', 'trust_rank': 2}),\n",
       " Document(page_content='Data Scientist\\nSan Jose, CA, USA, San Jose, CA\\nFull-time\\nCompany Description\\nWe are seeking a data scientist with at least 1 year of experience working with large data sets and 10 years of total\\nprofessi onal experience. This role is expected to translate business objectives into actionable data analysi s and\\ncommunicate ﬁndings clearly to technical and non-technical audiences\\nJob Description\\nRequired\\n• Analytical thinking;\\n• Understanding of statistics fundamentals;\\n• In-depth knowledge on the Hadoop stack (Ma p reduce, HDFS, Hive, Pig);\\n• In-depth knowledge on machine learning methods;\\n• Experience with scripting languages su ch as Python;\\n• Understanding of main statistical methods;\\n• Understanding of sampling techniques;\\n• Understanding of descriptive and inferential statistics concepts;\\n• Business domain experience in one of the following areas: retail, enterprise mobility, healthcare;\\nQualiﬁcations\\n• B.Sc. degree in Computer Science, Engineering, Ma thematics, Statistics or related ﬁeld is required\\n• M. Sc. / Ph.D degree in related ﬁeld is desirable.\\nAdditional Information\\nAll yo ur information will be kept conﬁdential according to EEO guidelines. Job Location\\nCookies Settings\\nPowered by\\n\\xa0(Data Processor)\\nPrivacy Policy\\xa0and\\xa0Terms of Use', metadata={'file_path': 'data/ApplyAll/Samsung Data Scientist _ SmartRecruiters-2.pdf', 'file_name': 'Samsung Data Scientist _ SmartRecruiters-2.pdf', 'source': 'applyall', 'trust_rank': 2}),\n",
       " Document(page_content=\"and familiarity with data manipula\\x00on and visualiza\\x00on libraries/tools. 3 - 8 years of experience in Sta\\x00s\\x00cal analysis, Data Modeling, Data Extrac\\x00on, Data Mining, and Data\\nManipula\\x00on.\\nSolid understanding of machine learning techniques (e.g., regression, classiﬁca\\x00on, clustering) and\\nexperience applying them to healthcare data. \\nHands-on experience with healthcare data standards (e.g., HL7, FHIR), electronic health records (EHR)\\nand other healthcare data sources.\\nExcellent problem-solving and analy\\x00cal skills, with the ability to communicate complex data insights in a\\nclear and accessible manner to stakeholders with varying levels of technical exper\\x00se.\\nThe ability to iden\\x00fy key challenges, formulate data-driven solu\\x00ons, and work with diverse stakeholders\\nto implement those solu\\x00ons.\\nExperience in working with sensi\\x00ve pa\\x00ent data while ensuring compliance and data security.\\nA passion for using data science to drive posi\\x00ve change and make a meaningful diﬀerence in people's\\nlives.\\nStrong people skills, speciﬁcally in collabora\\x00on and teamwork.\\nHigh level of curiosity, crea\\x00vity, technical vision, and problem-solving capabili\\x00es; have a customer-ﬁrst\\nand learner’s mindset, and value teaching others.\\nFamiliarity with big data tools and pla\\x00orms\\nJob Responsibili\\x00es\\nData Analysis and Model Development:\\nU\\x00lize advanced sta\\x00s\\x00cal and machine learning techniques to analyze healthcare data sets and extract\\nac\\x00onable insights.\\nDevelop predic\\x00ve models and algorithms to iden\\x00fy trends, pa\\x00erns, and correla\\x00ons in healthcare data.\\nEvaluate and validate model performance using appropriate metrics and methodologies.\\nLead ongoing tracking and monitoring of performance of decision systems and sta\\x00s\\x00cal models.\\nDevelop ETL (extract, transform, load) speciﬁca\\x00ons to go from raw data to research-ready datasets\\nCross-Func\\x00onal Collabora\\x00on and Strategy: Collaborate cross-func\\x00onally with stakeholders and leadership to design and implement data-driven\\nsolu\\x00ons that address complex healthcare challenges.\\nDevelop and drive adop\\x00on of enterprise-wide analy\\x00cs to support strategic execu\\x00on using prescrip\\x00ve\\nand predic\\x00ve analy\\x00cs with a focus on Healthcare access, Healthcare outcomes, and SDoH domains.\\nEngage and enable team members to access analy\\x00cs to facilitate faster data-driven decision-making\\nwherever and whenever they need it.\\nData Integra\\x00on and External Data Analysis:\\nAnalyze and incorporate external data sets that may augment the power of CareMessage internal data\\nsuch as social determinants of health data, claims data, environmental data, outcomes data.\\nCommunica\\x00on and Insights:\\nInterpret complex data analyses by applying ﬁndings to contextual se\\x00ngs; and developing insights,\\nreports, and presenta\\x00ons telling a compelling story to stakeholders to enable and inﬂuence decision-\\nmaking.\\nCon\\x00nuous Improvement and Learning:\\nStay updated with the latest advancements in data science, healthcare analy\\x00cs, and regulatory\\nrequirements to ensure compliance and relevance.\\nJob shadow other func\\x00onal areas to learn from domain experts.\\nWithin 1 Month You'll:\\nGain a founda\\x00onal understanding of our product, customers and pa\\x00ents.\\nMeet key internal stakeholders and begin to understand policies and protocols.\\nEstablish rapport with exis\\x00ng Engineers across various product teams.\\nBuild out basic understanding of exis\\x00ng data.\\nWithin 3 Months You'll: Gain a strong understanding of our technical environment and iden\\x00fy areas for growth in our processes,\\nsystems and/or tooling for data analysis.\\nDevelop ETL speciﬁca\\x00ons in conjunc\\x00on with a Data Engineer to allow the implementa\\x00on of a data\\npipeline to create a research-ready dataset.\\nWork with a business unit to create at two or more reports to facilitate faster data-driven decision-\\nmaking.\\nWithin 6 Months You'll:\\nHave a deep understanding of the product pla\\x00orm, our data needs and work in conjunc\\x00on with\\nmanagement to reﬁne the plan to meet our long term data goals.\\nU\\x00lize Data Science skills to generate a set of ac\\x00onable insights for a func\\x00onal area.\", metadata={'file_path': 'data/ApplyAll/CareMessage - Healthcare Data Scientist (Remote - US-Based).pdf', 'file_name': 'CareMessage - Healthcare Data Scientist (Remote - US-Based).pdf', 'source': 'applyall', 'trust_rank': 2}),\n",
       " Document(page_content='Data Scientist\\nat Venture Global LNG\\nArlington, VA\\n\\xa0\\n\\xa0\\nVenture Global LNG (“Venture Global”) is a long-term, low-cost provider of American-produced\\nliqueﬁed natural gas. The company’s Louisiana-based export projects service the global demand for\\nNorth American natural gas and support the long-term development of clean and reliable North\\nAmerican energy supplies. Using reliable, proven technology in an innovative plant design\\nconﬁguration, Venture Global’s modular, mid-scale plant design will replace traditional designs as it\\nallows for the same eﬃciency and operational reliability at signiﬁcantly lower capital cost.\\nThe Data Scientist is responsible for designing, developing, maintaining, and deploying machine\\nlearning, simulation, and optimization models using Databricks and Spark (PySpark). Strong data\\nengineering, communications, and self-management skills are a must.\\nThis position is for experienced candidates only. That means the candidate will have to demonstrate\\nreal world experience (not academia) as well as the expertise gained from that experience.\\nThe position reports to the Director of Business Intelligence and is structured within IT under the Vice\\nPresident of Applications.\\nThe position is located in Arlington, VA and requires working at the oﬃce ﬁve days a week.\\nResponsibilities\\nBuild end-to-end data science workﬂows, not just models, that provide quantiﬁable business\\nvalue to stakeholders.\\nWork the whole data science lifecycle: requirements, data generation, data transformation,\\nmodel building, model testing, model serving.\\nProvide software solutions that are automated and ﬂexible to future business demands.\\nMercilessly ﬁght technical debt and rework.\\nDevelop and leverage subject matter expertise in select portions of the business in order to\\nbetter design and execute projects.\\nQualiﬁcations\\nBachelor’s degree in analytical ﬁeld.\\n5 years experience data science work outside academia.\\n2 years experience in Spark (PySpark) OR experience in other Python data libraries plus some\\nexceptional demonstration of data science ability. Writing SQL or Pandas code in Spark does\\nnot count.\\nExcellent English.\\nExcellent communication skills, with a history of being able to communicate in oral, written, and\\npresentation form with senior stakeholders such as Directors, Vice Presidents, and the C-Suite.\\nThe ability to work in a completely self-directed manner. This includes the ability to learn\\ncomplex software by one’s self.\\nThe ability to organize complex work in a formal way so as to be able to keep track of multiple\\ncomplex projects for multiple stakeholders.\\nBroad understanding of how to write and deploy good code. This means being able to write\\ncode in functions, not just notebooks. Other topics are Git / version control, design of modular\\ncode to separate out constants and lookup tables, unit testing, and writing readable textbook-\\nstyle code that all team members can understand.\\nThorough understanding of basic data engineering concepts such as relational and nonrelational\\ndata stores, distributed computation, batch and stream processing, tables, keys, SQL vs Spark,\\ncardinality, transforms (groupby, agg, melt, pivot, window, join, union, merge, etc), partitions,\\ncaching, and so on.\\nThorough understanding of at least one Python visualization library such as matplotlib, seaborn,\\nplotly, holoviz, altair, etc. Excellent understanding of both business-centric visualization and\\nApply Now\\nPrivacy - Terms Apply for this Job* Required\\nFirst Name *\\nLast Name *\\nEmail *\\nPhone *\\nLocation (City) *\\n\\xa0scientiﬁc visualization, including how to best display quantitative information to nontechnical\\naudiences. Ideally, a mature understanding of the aesthetics of visualization.\\nThorough understanding of applied data science in the form of machine learning. Knowledge of\\nthe statistical principles that underpin machine learning, the basic types of machine learning\\nmodels, and the proper use of Python ML libraries such as scikit-learn and spark.ml / mllib.\\nPreferred Qualiﬁcations\\nKnowledge of additional data science methodologies beyond vanilla machine learning:\\nsimulation methodologies such as system dynamics (SD), agent-based modeling (ABM), and\\ndiscrete event simulation (DES); deep learning; the application of ML / DL to unstructured data\\nsuch as text, audio, images, and video; and optimization.\\nDemonstrated expertise in applying one or more data science methodologies in an advanced', metadata={'file_path': 'data/ApplyAll/Job Application for Data Scientist at Venture Global LNG.pdf', 'file_name': 'Job Application for Data Scientist at Venture Global LNG.pdf', 'source': 'applyall', 'trust_rank': 2}),\n",
       " Document(page_content='Apply To Position\\n(/p/7036a10fb0d7-remote-data-\\nscientist/apply)\\nUse My Indeed Resume\\nApply Using LinkedIn\\n(https://app.breezy.hr/api/apply/linkedin?\\nposition_id=7036a10fb0d7)\\nView lar ger map\\nMap data ©2024 Google\\n\\ue61a (https://twitter.com/search?\\nq=%40SolutionsParam&src=typd)\\n\\uf082\\n(https://www.facebook.com/Recruiting-\\nAs-A-Service-RaaS-\\n108405177250063/?\\nmodal=admin_todo_tour)\\n\\uf08c\\n(https://www.linkedin.com/company/param-\\nsolutions)\\n\\uf09e (https://param-\\nsolutions.com/blog/latest)Job Openings (/)〉Remote Data Scientist\\nJob Description:\\nData Scientists will be expected to:\\nPerform hands-on analysis and modeling involving the\\ncreation of intervention hypotheses and experiments,\\nassessment of data needs and available sources,\\ndetermination of optimal analytical approaches, performance\\nof exploratory data analysis, and feature generation (e.g.,\\nidentification, derivation, aggregation).\\nCollaborate with mission stakeholders to define, frame, and\\nscope mission challenges where big data interventions may\\noffer important mitigations and develop robust project plans\\nwith key milestones, detailed deliverables, robust work\\ntracking protocols, and risk mitigation strategies.\\nDemonstrate proficiency in extracting, cleaning, and\\ntransforming CBP transactional and mission data associated\\nwithin an identified problem space to build predictive models\\nas well as develop appropriate supporting documentation.\\nLeverage expert knowledge of a variety of statistical and\\nmachine learning techniques and methods to define and\\ndevelop programming algorithms; train, evaluate, and deploy\\npredictive analytics models that directly inform mission\\ndecisions.\\nExecute projects including those intended to identify patterns and/or\\nanomalies in large datasets; perform automated text/data classification\\nand categorization as well as entity recognition, resolution and extraction;\\nand named entity matching.\\nBrief project management, technical design, and outcomes to both\\ntechnical and non-technical audiences including senior government\\nstakeholders throughout the model development/ project lifecycle through\\nwritten as well as in-person reporting.Remote Data Scientist\\n\\uf041Ashburn, VA - \\uf1ebRemote (Any Location)\\uf0f7Full-TimeCompany Website (https://www.shuvel.net/)\\ue61a (https://twitter.com/search?q=%40SolutionsParam&src=typd)\\n\\uf082 (https://www.facebook.com/Recruiting-As-A-Service-RaaS-108405177250063/?modal=admin_todo_tour)\\n\\uf08c (https://www.linkedin.com/company/param-solutions)\\uf09e (https://param-solutions.com/blog/latest)\\n (/) Basic Qualifications:\\nProficiency with statistical software packages: R\\nExperience with programming languages: R, SQL\\nExperience constructing and executing queries to extract data for\\nexploratory data analysis and model development\\nExperience performing training set construction, analysis, and data mining\\nExperience with unsupervised machine learning techniques and methods\\nSignificant experience in developing machine learning models and\\napplying advanced analytics solutions to solve complex business problems\\nProficiency with SQL programming\\nExperience with unsupervised and supervised machine learning\\ntechniques and methods\\nExperience working with large-scale (e.g., terabyte and petabyte)\\nunstructured and structured data sets and databases\\nExperience performing data mining, analysis, and training set construction.\\nDesired Qualifications:\\nExperience with programming languages including: Python, Scala, Java\\nExperience constructing and executing queries to extract data in support\\nof EDA and model development\\nProficiency with statistical software packages including: SAS, SPSS\\nModeler, R, WEKA, or equivalent\\nProficiency with Unsupervised Machine Learning methods including\\nCluster Analysis (e.g., K-means, K-nearest Neighbor, Hierarchical, Deep\\nBelief Networks, Principal Component Analysis), Segmentation, etc.\\nExperience with Natural Language Processing (NLP), computational\\nlinguistics, Entity extraction, named entity recognition (NER), name\\nmatching, disambiguation, Latent Semantic Analysis (LSA) and Latent\\nDirichlet Allocation (LDA).\\nProficiency with Supervised Machine Learning methods including Decision', metadata={'file_path': 'data/ApplyAll/Remote Data Scientist at Shuvel Digital.pdf', 'file_name': 'Remote Data Scientist at Shuvel Digital.pdf', 'source': 'applyall', 'trust_rank': 2}),\n",
       " Document(page_content='neural networks, and clustering techniques.\\nDeploying predictive models and integrating them into business processes and applications.\\nValidating and optimizing model performance upon deployment and tracking over time as necessary .\\nPresenting complex analysis results tailored to dif ferent audiences (e.g. technical, manager , executive) in a\\nhighly consumable and actionable form including the use of data visualizations.\\nQualiﬁcations\\nT echnical:\\n3+ years in a hands-on role performing advanced predictive analytics using tools like Python, R, or Scala.\\n3+ years writing simple to complex SQL  queries to obtain data from multiple source systems.\\n3+ years using data mining methods, such as clustering analysis and anomaly detection, to understand\\ndata patterns and select appropriate predictive techniques.\\nExperience with applied machine learning (tree-based methods, ensemble methods, neural networks/deep\\nlearning)\\nProﬁcient understanding of relational (e.g. Oracle, SQL  Server , PostgreSQL) and Big Data distributed\\nstructures (Hadoop/Spark) in order to source data ef fectively .\\nExperience using natural language processing techniques preferred.\\nExperience using advanced analytics techniques for fraud detection and prevention preferred.\\nExperience building machine learning models for production environment preferred.\\nNon-T echnical:\\nExcellent communication skills to be able to interact directly with non-technical client stakeholders and act\\nin a business-to-technical translation role.\\nExperience working in an onsite client technical consulting environment preferred.\\nExperience working within the Agile Scrum Framework.\\nSelf-motivated and self-managing.\\nProﬁcient in creating reasonable and accurate time estimates for assigned tasks.\\nUnderstanding of DevOps Research and Assessment (DORA) and the capabilities within the DORA\\ncapability catalog is encouraged.\\nExcella is an equal opportunity/affirmative action employer. All qualified applicants will receive consideration for\\nemployment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability,\\nprotected veteran status, age, or any other characteristic protected by law. Excella is committed to providing access, equal\\nopportunity, and reasonable accommodation for individuals with disabilities in employment, its services, programs, and\\nactivities. To request reasonable accommodation to participate in the job application or interview process,\\ncontactRecruiting@excella.comor 703-840-8600. Know Your Rights\\nPay Transparency Notice', metadata={'file_path': 'data/ApplyAll/Job Application for Data Scientist at Excella.pdf', 'file_name': 'Job Application for Data Scientist at Excella.pdf', 'source': 'applyall', 'trust_rank': 2}),\n",
       " Document(page_content='CyberCoders logo\\nData Scientist\\nNew York, NY\\nFull-time\\nCompany Description\\nMarketing and Analytics company focused on driving results around personalization...\\nJob Description\\nAs a member of our Data Science team, you will challenge the way our company thinks about our current and future\\nspace in the market. You will lead research projects, create awesome and revolutionary products, and share your\\ninfectious enthusiasm. You love building mathematical and probabilistic models, computer science algorithms, and you\\nhave exposure to (multi-terabyte) big data\\nQualiﬁcations\\nImplementation experience with supervised and unsupervised machine learning algorithms, such as tree-based models\\nlike Random Forests or Decision Trees, SVM, PCA, SVD.\\nReal statistical experimental design skills with keen awareness of their assumptions and ﬂaws; you are an expert at\\nidentifying correlation vs. causation in data sets.\\nExperience with statistical methods and analysis such as bias vs. variance tradeoﬀs, Bayesian Stats, probability\\ndistributions, regressions, etc.\\nCoding experience in a production environment. You know algorithms and data structures, parallelism and concurrency, at\\nleast 1 computer language, and computer science topics\\nFamiliarity with parallelization frameworks such as Apache Spark, Sun Grid Engine, IPython Parallel, Hadoop.\\nAbility to productize our data and revolutionize the way we think about our data and business\\nYou are a team player. You own projects from start to ﬁnish, deploy code, and coordinate work with other teams. You love\\nhard problems as much as we do!\\nAdditional Information\\nAll your information will be kept conﬁdential according to EEO guidelines.\\nCookies Settings Posted by\\nBryan McQuilkin', metadata={'file_path': 'data/ApplyAll/CyberCoders Data Scientist _ SmartRecruiters.pdf', 'file_name': 'CyberCoders Data Scientist _ SmartRecruiters.pdf', 'source': 'applyall', 'trust_rank': 2}),\n",
       " Document(page_content=\"Apply To Position\\n(/p/31a42bac1deb-data-\\nscientist/apply)\\nUse My Indeed Resume\\nApply Using LinkedIn\\n(https://app.breezy.hr/api/apply/linkedin?\\nposition_id=31a42bac1deb)\\nView lar ger map\\nMap data ©2024 Google\\n\\ue61a (https://twitter.com/VictoryCto)\\n\\uf08c\\n(https://www.linkedin.com/company/victory-\\ncto/)Job Openings (/)〉Data Scientist\\nAbout the Data Scientist position\\nWe are looking for a skilled Data Scientist who will help us\\nanalyze large amounts of raw information to find patterns\\nand use them to optimize our performance. You will build\\ndata products to extract valuable business insights, analyze\\ntrends and help us make better decisions.\\nWe expect you to be highly analytical with a knack for\\nanalysis, math and statistics, and a passion for machine-\\nlearning and research. Critical thinking and problem-solving\\nskills are also required.\\nData Scientist responsibilities are:\\nResearch and detect valuable data sources and automate\\ncollection processes\\nPerform preprocessing of structured and unstructured\\ndata\\nDesign, implement and deliver maintainable and high-quality code using\\nbest practices (e.g. Git/Github, Secrets, Configurations, Yaml/JSON)\\nReview large amounts of information to discover trends and patterns\\nCreate predictive models and machine-learning algorithms\\nModify and combine different models through ensemble modeling\\nOrganize and present information using data visualization techniques\\nDevelop and suggest solutions and strategies to business challenges\\nWork together with engineering and product development teamsData Scientist\\n\\uf041Austin, TX - \\uf1ebRemote (Any Location)\\uf0f7Full-TimeCompany Website (https://www.victorycto.com)\\ue61a (https://twitter.com/VictoryCto)\\n\\uf08c (https://www.linkedin.com/company/victory-cto/)\\n (/) breezy (https://breezy.hr/m/portal?utm_campaign=portal_referral&cpn=Victory)Data Scientist requirements are:\\n3+ years' experience of working on Data Scientist or Data Analyst\\nposition\\nSignificant experience in data mining, machine-learning and operations\\nresearch\\nExperience with data modeling, design patterns, building highly scalable\\nand secured solutions preferred\\nPrior experience installing data architectures on Cloud providers (e.g.\\nAWS,GCP,Azure), using DevOps tools and automating data pipelines\\nGood experience using business intelligence/visualization tools (such as\\nTableau), data frameworks (such as Hadoop, DataFrames, RDDs,\\nDataclasses) and data formats (CSV, JSON, Parquet, Avro, ORC)\\nAdvanced knowledge of R, SQL and Python; familiarity with Scala, Java\\nor C++ is an asset\\nMA or PhD degree in Computer Science, Engineering or other relevant\\narea; graduate degree in Data Science or other quantitative field is\\npreferred\\nMust be a U.S. Citizen\\nApply To Position (/p/31a42bac1deb-data-scientist/apply)\\n Use My Indeed ResumeApply Using LinkedIn (https://app.breezy.hr/api/a\\nPowered byCompany Website (https://www.victorycto.com)\\ue61a (https://twitter.com/VictoryCto)\\n\\uf08c (https://www.linkedin.com/company/victory-cto/)\\n (/)\", metadata={'file_path': 'data/ApplyAll/Data Scientist at Victory.pdf', 'file_name': 'Data Scientist at Victory.pdf', 'source': 'applyall', 'trust_rank': 2}),\n",
       " Document(page_content=\"Data Scientist\\nat BrightAI\\xa0(View all jobs)\\nUnited States (Remote)\\nBrightAI, at the forefront of technological advancement, seeks a proﬁcient Data Scientist to unravel insights from complex datasets,\\nemploying advanced analytics and machine learning techniques. Our mission is to redeﬁne intelligent automation, and we are expanding\\nour team to welcome a talented and technically adept individual who is passionate about pushing the boundaries of innovation. As we\\ncontinue to push the boundaries of what's possible, we are looking for a skilled Data Scientist who shares our passion for harnessing\\ndata's potential to shape the future.\\nAs a Data Scientist at BrightAI, you will play a pivotal role in extracting meaningful insights from diverse datasets, employing advanced\\nanalytics and machine learning techniques. You will collaborate with cross-functional teams to develop data-driven solutions that\\ncontribute to the advancement of our cutting-edge projects. This position oﬀers an exciting opportunity to work at the intersection of data\\nscience, artiﬁcial intelligence, and innovative technologies.\\nKey Responsibilities:\\nApply statistical analysis and machine learning techniques to extract actionable insights from complex datasets\\nDevelop predictive models and algorithms to solve business challenges and optimize processes\\nExplore and preprocess large datasets to uncover hidden patterns and trends\\nCreate compelling visualizations to communicate insights eﬀectively to both technical and non-technical stakeholders\\nCollaborate with data engineers and software developers to implement and deploy machine learning models into production\\nenvironments\\nContinuously optimize and reﬁne models to enhance accuracy and eﬃciency\\nIdentify relevant features and variables to improve model performance and contribute to feature engineering strategies\\nWork closely with interdisciplinary teams, including software developers, engineers, and domain experts, to integrate data science\\nsolutions into broader projects\\nAdhere to data governance standards, ensuring the responsible and ethical use of data throughout the development lifecycle\\nStay abreast of the latest developments in data science, machine learning, and related ﬁelds, applying new techniques to solve\\ncomplex problems\\nQualiﬁcations:\\n7+ years of experience in data science (Data Analyst or Data Scientist)\\nMaster's or Ph.D. in Data Science, Computer Science, Statistics, or a related ﬁeld\\nProven experience in data science, statistical analysis, and machine learning including pattern recognition and predictive modeling\\nProﬁciency in programming languages such as Python or SQL\\nStrong understanding of data manipulation, feature engineering, and model evaluation techniques\\nExperience with machine learning frameworks (e.g., TensorFlow, PyTorch) is a plus\\nExcellent communication skills to convey complex ﬁndings and insights to diverse audiences\\nAbility to work collaboratively in a fast-paced, innovative environment\\nBonus Criteria:\\nCandidates with the following additional qualiﬁcations and experiences will be given special consideration:\\nExperience with big data technologies and distributed computing\\nContinued education with professional certiﬁcations\\nKnowledge of natural language processing (NLP) and deep learning techniques.\\nBackground in developing data-driven solutions for real-world applications\\nContributions to open-source projects or active participation in the data science community #li-remote\", metadata={'file_path': 'data/ApplyAll/Job Application for Data Scientist at BrightAI.pdf', 'file_name': 'Job Application for Data Scientist at BrightAI.pdf', 'source': 'applyall', 'trust_rank': 2}),\n",
       " Document(page_content=\"http://www.ubertal.com logo\\nData Scientist\\nEmployees can work remotely\\nFull-time\\nCompany Description\\nWe are passi onate people with an expert understanding of the digital consu mer, data sciences, global telecom business,\\nand emerging ﬁnancial services. And we believe that we can make the world a better place.\\nJob Description\\nLooking for candidate making a career in Data Science with experience applying advanced statistics, data mining and\\nmachine learning algorithms to make data-driven predictions using programming languages like Python (including: Numpy,\\nPandas, Scikit-learn, Ma tplotlib, Seaborn), SQL (Postgresq l). Experience with ElasticSearch, information/document\\nretrieval, natural language processi ng is a plus. Experience with various machine learning methods (classi ﬁcation,\\nclustering, natural language processi ng, ensemble methods, outlier analysi s) and parameters that aﬀect their performance\\nalso  helps. You will leverage yo ur strong collaboration skills and ability to extract valuable insights from highly complex\\ndata sets to ask the right questions and ﬁnd the right answe rs.\\n\\xa0\\nQualiﬁcations\\nQualiﬁcations\\n·\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 Bachelor's degree or equivalent experience in quantative ﬁeld (Statistics, Ma thematics, Computer Science,\\nEngineering, etc.)\\n·\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 At least 2 years' of experience in quantitative analytics or data modeling\\n·\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 Some understanding of predictive modeling, machine-learning, clustering and classi ﬁcation techniques, and\\nalgorithms\\n·\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 Fluency in these programming languages (Python, SQL), Javascript/HTML /CSS/Web Development nice to have.\\n·\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 Familiarity with data science frameworks and visu alization tools (Pandas, Visu alizations (matplotlib, altair, etc),\\nJupyter Notebooks)\\nAdditional Information\\nResponsibilities\\n·\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 Analyze raw data: asse ssi ng quality, cleansing, structuring for downstream processi ng\\n·\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 Design accurate and scalable prediction algorithms\\n·\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 Collaborate with engineering team to bring analytical prototyp es to production\\n·\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 Generate actionable insights for business improvements tion will be kept conﬁdential according to EEO guidelines.\\nJob Location\\nCookies Settings\\nPosted by\\nRavi Malviya\\nPowered by\\n\\xa0(Data Processor)\\nPrivacy Policy\\xa0and\\xa0Terms of Use\", metadata={'file_path': 'data/ApplyAll/www.ubertal.com Data Scientist _ SmartRecruiters.pdf', 'file_name': 'www.ubertal.com Data Scientist _ SmartRecruiters.pdf', 'source': 'applyall', 'trust_rank': 2}),\n",
       " Document(page_content=\"Apply To Position (/p/9cf52c7f0226-\\ndata-scientist/apply)\\nUse My Indeed Resume\\nApply Using LinkedIn\\n(https://app.breezy.hr/api/apply/linkedin?\\nposition_id=9cf52c7f0226)\\nView lar ger map\\nMap data ©2024 Google\\n\\uf08c\\n(https://www.linkedin.com/company/themis-\\ninsight-llc/)Job Openings (/)〉Data Scientist\\nThemis Insight solves difficult business, IT, and analytic\\nproblems by addressing the whole problem – not just the\\nsymptoms – using interdisciplinary approaches that are both\\npractical and innovative. We provide fresh alternatives to\\nordinary, mainstream consulting firms through small, highly\\nskilled, and hand-picked teams that can meet clients' needs\\nin any industry. Our broad interdisciplinary understanding\\nallows us to provide the right solution, even if it is from\\noutside the industry or traditionally defined problem space.\\nWe bring Public and Private, Civilian and Military expertise to\\nevery case.\\nWe are hiring a Data Scientist to work in Fort Meade, MD.\\nPosition location is subject to change based on central MD\\nclient's needs.\\nRequired: TS/SCI with a Polygraph\\nEmploy some combination (2 or more) of the following skill\\nareas:\\n1. Foundations: (Mathematical, Computational, Statistical)\\n2. Data Processing: (Data management and curation, data description\\nand visualization, workflow and reproducibility)\\n3. Modeling, Inference, and Prediction: (Data modeling and assessment,\\ndomain-specific considerations)\\nDevise strategies for extracting meaning and value from large datasets.\\nMake and communicate principled conclusions from data using elements\\nof mathematics, statistics, computer science, and applications specific\\nknowledge. Through analytic modeling, statistical analysis, programming,\\nand/or another appropriate scientific method, develop and implement\\nqualitative and quantitative methods for characterizing, exploring, and\\nassessing large datasets in various states of organization, cleanliness, and\\nstructure that account for the unique features and limitations inherent in\\nNSA/CSS data holdings. Translate practical mission needs and analyticData Scientist\\n\\uf041Fort Meade, MD\\uf0f7Full-TimeCompany Website (http://www.themisinsight.com)\\uf08c (https://www.linkedin.com/company/themis-insight-llc/)\\n (/) questions related to large datasets into technical requirements and,\\nconversely, assist others with drawing appropriate conclusions from the\\nanalysis of such data. Effectively communicate complex technical\\ninformation to non-technical audiences. Make informed recommendations\\nregarding competing technical solutions by maintaining awareness of the\\nconstantly-shifting NSA/CSS collection, processing, storage and analytic\\ncapabilities and limitations.\\nIndividual Capabilities/Experience Required:\\nA Bachelor’s degree and 3 years of relevant experience. An Associate’s\\ndegree plus 5 years of relevant experience may be considered for\\nindividuals with in-depth experience that is clearly related to the\\nposition.\\nDegree must be in Mathematics, Applied Mathematics, Statistics,\\nApplied Statistics, Machine Learning, Data Science, Operations\\nResearch, or Computer Science. A degree in a related field (e.g.,\\nComputer Information Systems, Engineering), a degree in the\\nphysical/hard sciences (e.g. physics, chemistry, biology, astronomy), or\\nother science disciplines with a substantial computational component\\n(i.e., behavioral, social, and life) may be considered if it includes a\\nconcentration of coursework (typically 5 or more courses) in advanced\\nmathematics (typically 300 level or higher; such as linear algebra,\\nprobability and statistics, machine learning) and/or computer science\\n(e.g., algorithms, programming, data structures, data mining, artificial\\nintelligence). College-level Algebra or other math courses intended to\\nmeet a basic college level requirement, or upper level math courses\\ndesignated as elementary or basic do not count.\\nNote: A broader range of degrees will be considered if accompanied by\\na Certificate in Data Science from an accredited college/university/\\nRelevant experience must be in designing/implementing machine\\nlearning, data science, advanced analytical algorithms, programming\\n(skill in at least one high-level language (e.g. Python)), statistical\\nanalysis (e.g. variability, sampling error, inference, hypothesis testing,\\nEDA, application of linear models), data management (e.g. data\\ncleaning and transformation), data mining, data modeling and\", metadata={'file_path': 'data/ApplyAll/Data Scientist at Themis Insight.pdf', 'file_name': 'Data Scientist at Themis Insight.pdf', 'source': 'applyall', 'trust_rank': 2}),\n",
       " Document(page_content=\"Data Scien\\x00st Level 2 (Telework)\\nAnnapolis Junction, Maryland\\nTKO Team /Data Scientist (Full-Time) /Hybrid\\nWe are seeking a Data Scien\\x00st with analy\\x00c development skills to support a highly visible cyber sensor and\\nanaly\\x00c moderniza\\x00on program. The candidate will work with a team to analyze and characterize large data\\nsets, create data visualiza\\x00ons, and iden\\x00fy anomalous/interes\\x00ng behavior.\\nThe successful candidate will have experience with analysis in the cyber domain and discovery opera\\x00ons,\\nand have experience with algorithm design and development in cloud environments.\\nA data scien\\x00st will develop machine learning, data mining, sta\\x00s\\x00cal and graph-based algorithms to analyze\\nand make sense of datasets; prototype or consider several algorithms and decide upon ﬁnal model based on\\nsuitable performance metrics; build models or develop experiments to generate data when training or\\nexample datasets are unavailable; generate reports and visualiza\\x00ons that summarize datasets and provide\\ndata-driven insights to customers; partner with subject ma\\x00er experts to translate manual data analysis into\\nautomated analy\\x00cs; implement prototype algorithms within produc\\x00on frameworks for integra\\x00on into\\nanalyst workﬂows. \\n** This posi\\x00on will have up to 60% telework.\\nCapabili\\x00es\\nProduce data visualiza\\x00ons that provide insight into dataset structure and meaning\\nWork with subject ma\\x00ers experts (SMEs) to iden\\x00fy important informa\\x00on in raw data and develop\\nscripts that extract this informa\\x00on from a variety of data formats (e.g., SQL tables, structured metadata, network logs)\\nIncorporate SME input into feature vectors suitable for analy\\x00c development and tes\\x00ng\\nTranslate customer qualita\\x00ve analysis process and goals into quan\\x00ta\\x00ve formula\\x00ons that are coded\\ninto so\\x00ware prototypes\\nDevelop and implement sta\\x00s\\x00cal, machine learning, and heuris\\x00c techniques to create descrip\\x00ve,\\npredic\\x00ve, and prescrip\\x00ve analy\\x00cs\\nDevelop sta\\x00s\\x00cal tests to make data-driven recommenda\\x00ons and decisions\\nDevelop experiments to collect data or models to simulate data when required data are unavailable\\nDevelop feature vectors for input into machine learning algorithms\\nIden\\x00fy the most appropriate algorithm for a given dataset and tune input and model parameters\\nEvaluate and validate the performance of analy\\x00cs using standard techniques and metrics (e.g. cross\\nvalida\\x00on, ROC curves, confusion matrices)\\nOversee the development of individual analy\\x00c eﬀorts and guide team in analy\\x00c development process\\nGuide analy\\x00c development toward solu\\x00ons that can scale to large datasets\\nPartner with so\\x00ware engineers and cloud developers to develop produc\\x00on analy\\x00cs\\nDevelop and train machine learning systems based on sta\\x00s\\x00cal analysis of data characteris\\x00cs to\\nsupport mission automa\\x00on\\nRequired Qualiﬁca\\x00ons\\nTS/SCI with Agency Appropriate Polygraph\\nBachelor's and Master's degree from an accredited college or university in a quan\\x00ta\\x00ve discipline (e.g.,\\nsta\\x00s\\x00cs, mathema\\x00cs, opera\\x00ons research, engineering or computer science).\\nFive years of experience analyzing datasets and developing analy\\x00cs, ﬁve years of experience\\nprogramming with data analysis so\\x00ware such as R, Python, SAS, or MATLAB. An addi\\x00onal two years of\\nexperience in so\\x00ware development, cloud development, analyzing datasets, or developing descrip\\x00ve,\\npredic\\x00ve, and prescrip\\x00ve analy\\x00cs can be subs\\x00tuted for a Master's degree.\\nA PhD from an accredited college or university in a quan\\x00ta\\x00ve discipline can be subs\\x00tuted for three\\nyears of experience. Required Technical Skills\\nPython and object oriented programming\\nAnaly\\x00c development within Linux environment\\nExperience with DataFrames (Pandas or Spark)\\nUnderstanding of data science concepts\\nDesired Technical Skills\\nPySpark and/or distributed compu\\x00ng\\nExperience working in cloud environments (Azure, AWS)\\nWyetech, LLC is an Equal Opportunity Employer. All qualiﬁed applicants will receive considera\\x00on for\\nemployment without regard to race, color, religion, sex, sexual orienta\\x00on, gender iden\\x00ty, na\\x00onal origin,\\nor protected veteran status and will not be discriminated against on the basis of disability.\", metadata={'file_path': 'data/ApplyAll/Wyetech - Data Scientist Level 2 (Telework).pdf', 'file_name': 'Wyetech - Data Scientist Level 2 (Telework).pdf', 'source': 'applyall', 'trust_rank': 2}),\n",
       " Document(page_content='Apply To Position\\n(/p/08e62fc3aad1-data-\\nscientist/apply)\\nUse My Indeed Resume\\nApply Using LinkedIn\\n(https://app.breezy.hr/api/apply/linkedin?\\nposition_id=08e62fc3aad1)\\nView lar ger map\\nMap data ©2024 Google\\n\\uf082\\n(https://www.facebook.com/ConcurrentTechnologiesCorporation/)\\n\\uf08c\\n(http://www.linkedin.com/companies/5512)Job Openings (/)〉Data Scientist\\nDATA SCIENTIST\\nConcurrent Technologies Corporation\\nNorthern Virginia\\nMinimum Clearance Required: TS/SCI with Polygraph\\nClearance Level Must Be Able to Obtain: TS/SCI with\\nPolygraph\\nConcurrent Technologies Corporation (CTC) is seeking highly\\ntalented and driven Data Scientists with exceptional Python\\nprogramming skills. This position offers a unique opportunity\\nto work on exciting and impactful projects that address\\ncritical challenges within the Intelligence Community (IC). You\\nwill play a crucial role in transforming vast amounts of\\nstructured and unstructured data into actionable insights\\nthrough advanced data manipulation, machine learning, and\\ninnovative analytical techniques.\\nKey Responsibilities:\\nData Integration and Analysis:\\nWrite sophisticated scripts to integrate diverse datasets.\\nConduct exploratory data analysis to uncover hidden patterns and\\nrelationships.\\nMachine Learning and Predictive Modeling:\\nDevelop and deploy machine learning models to train predictive\\nanalytics.\\nApply the right combination of tools and techniques to transform\\ndisparate data points into meaningful insights.\\nData Enrichment and Prioritization:\\nEnrich and prioritize data to discover relationships and correlations.Data Scientist\\n\\uf041Springfield, VA\\uf0f7Full-Time\\uf0f7Information Technology DivisionCompany Website (https://www.ctc.com) Employees (/team/portal)\\n\\uf082 (https://www.facebook.com/ConcurrentTechnologiesCorporation/)\\uf08c (http://www.linkedin.com/companies/5512)\\n (/) Enable the identification of structures, roles, and key relationships\\nrelated to actors, devices, or facilities.\\nSituational Awareness and Data Unification:\\nProvide situational awareness by unifying data into a coherent and\\naccurate context.\\nCreate comprehensive visualizations that present data insights clearly\\nand concisely.\\nSystems Modeling and Business Analytics:\\nPerform systems modeling to create computational analogs of real-\\nworld systems.\\nGenerate business analytics to support data-driven decision-making\\nand enhance intelligence operations.\\nBasic Qualifications:\\nEducational Background:\\nBachelor’s degree in Mathematics, Physical Science, Software\\nEngineering, Computer Science, or a related field with 4-6 years of\\nrelevant experience, Master’s degree with 2-4 years of experience, or\\nPhD with 0-2 years of experience.\\nTechnical Expertise:\\nDemonstrated knowledge in two or more of the following areas:\\nApplied Mathematics (e.g., probability and statistics, multivariable\\ncalculus, linear algebra, differential equations, stochastic\\nprocesses, graph theory).\\nComputer Programming (e.g., scripting, data parsing/ETL, artificial\\nintelligence, machine learning, natural language processing,\\nsoftware versioning, distributed computing).\\nData Visualization (e.g., dashboard creation, network analysis,\\nGIS/geospatial analysis, telemetry analysis).\\nPreferred Qualifications:\\nInnovation and Problem-Solving:\\nDemonstrated creativity and innovation in solving complex problems.\\nAbility to organize and manage relevant information using advanced\\ndata management tools.\\nHypothesis Testing and Application Development:\\nDevelop hypotheses about data and create software applications to\\ntest them.\\nSkilled in data storytelling through graphical, verbal, or written\\nnarratives.\\nTeam Collaboration:\\nMotivated to work collaboratively and effectively within a dynamic\\nteam environment.\\nWhy CTC?Company Website (https://www.ctc.com) Employees (/team/portal)\\n\\uf082 (https://www.facebook.com/ConcurrentTechnologiesCorporation/)\\uf08c (http://www.linkedin.com/companies/5512)\\n (/) breezy (https://breezy.hr/m/portal?utm_campaign=portal_referral&cpn=Concurrent Technologies Corporation)Our teams at CTC are passionate and thrive on collaboration in a team\\nenvironment\\nWhen we encounter a difficult problem, we have a variety of talented', metadata={'file_path': 'data/ApplyAll/Data Scientist at Concurrent Technologies Corporation.pdf', 'file_name': 'Data Scientist at Concurrent Technologies Corporation.pdf', 'source': 'applyall', 'trust_rank': 2}),\n",
       " Document(page_content=\"Data Scien\\x00st 3\\nAnnapolis Junction, Maryland\\nVV Team /Data Scientist (Full-Time) /On-Site\\nDevise strategies for extrac\\x00ng meaning and value from large datasets. Make and communicate principled\\nconclusions from data using elements of mathema\\x00cs, sta\\x00s\\x00cs, computer science, and applica\\x00on speciﬁc\\nknowledge. Through analy\\x00c modeling, sta\\x00s\\x00cal analysis, programming, and/or another appropriate\\nscien\\x00ﬁc method, develop and implement qualita\\x00ve and quan\\x00ta\\x00ve methods for characterizing,\\nexploring, and assessing large datasets in various states of organiza\\x00on, cleanliness, and structure that\\naccount for the unique features and limita\\x00ons inherent in Agency data holdings. Translate prac\\x00cal mission\\nneeds and analy\\x00c ques\\x00ons related to large datasets into technical requirements and, conversely, assist\\nothers with drawing appropriate conclusions from the analysis of such data. Eﬀec\\x00vely communicate\\ncomplex technical informa\\x00on to non-technical audiences. Make informed recommenda\\x00ons regarding\\ncompe\\x00ng technical solu\\x00ons by maintaining awareness of the constantly-shi\\x00ing Agency collec\\x00on,\\nprocessing, storage and analy\\x00c capabili\\x00es and limita\\x00ons.\\nEmploy some combina\\x00on (2 or more) of the following skill areas:\\nI. Founda\\x00ons: (Mathema\\x00cal, Computa\\x00onal, Sta\\x00s\\x00cal) \\n2. Data Processing: (Data management and cura\\x00on, data descrip\\x00on and visualiza\\x00on, workﬂow and\\nreproducibility)\\n3. Modeling, Inference, and Predic\\x00on: (Data modeling and assessment, domain-speciﬁc considera\\x00ons)\\nRequired Qualiﬁca\\x00ons\\nTS/SCI with Agency Appropriate Polygraph\\nBachelor’s Degree with 10 years of relevant experience Associates degree with 12 years of relevant experience\\nBachelor's\\u202fDegree must be in Mathema\\x00cs, Applied Mathema\\x00cs Sta\\x00s\\x00cs, Applied Sta\\x00s\\x00cs, Machine\\nlearning, Data Science, Opera\\x00ons Research, or Computer Science or a degree in a related ﬁeld\\n(Computer Informa\\x00on Systems, Engineering), a degree in the physical/hard sciences (e.g. physics,\\nchemistry, biology, astronomy), or other science   disciplines with a substan\\x00al computa\\x00onal component\\n(i.e. behavioral, social, or life) may be considered if it included a concentra\\x00on of coursework (5 or more\\ncourses) in advanced Mathema\\x00cs (typically 300 level or higher, such as linear algebra, probability and\\nsta\\x00s\\x00cs, machine learning)  and/or computer science (e.g. algorithms, programming, , data   structures,\\ndata mining, ar\\x00ﬁcial intelligence).  College-level requirement, or upper-level math courses designated as\\nelementary or basic do not count\\nA broader range of degrees will be considered if accompanied by a Cer\\x00ﬁcate in Data Science from an\\naccredited college/university\\nRelevant Experience\\nRelevant experience must be in designing/implemen\\x00ng machine learning, data science, advanced\\nanaly\\x00cal   algorithms, programming (skill in at least one high-level language (e.g. Python)), sta\\x00s\\x00cal\\nanalysis (e.g. variability, sampling error, inference, hypothesis tes\\x00ng, EDA, applica\\x00on of linear models),\\ndata management (e.g. data cleaning and transforma\\x00on), data mining, data modeling and assessment,\\nar\\x00ﬁcial intelligence, and/or so\\x00ware engineering. Experience in more than one area is strongly preferred\\nWyetech, LLC is an Equal Opportunity Employer. All qualiﬁed applicants will receive considera\\x00on for\\nemployment without regard to race, color, religion, sex, sexual orienta\\x00on, gender iden\\x00ty, na\\x00onal origin,\\nor protected veteran status and will not be discriminated against on the basis of disability.\\nJobs powered by\", metadata={'file_path': 'data/ApplyAll/Wyetech - Data Scientist 3.pdf', 'file_name': 'Wyetech - Data Scientist 3.pdf', 'source': 'applyall', 'trust_rank': 2})]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_multi.invoke(\"What skills are required for the role of a data scientist?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    ")\n",
    "from langchain.schema import SystemMessage\n",
    "from langchain.prompts import MessagesPlaceholder, HumanMessagePromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent,OpenAIFunctionsAgent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tool for searching reviews\n",
    "tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"search_listings\",\n",
    "    \"Search job listings for relevant information.\"\n",
    ")        \n",
    "tools = [tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a helpful data analyst for answering questions related to job listings. '),\n",
       " MessagesPlaceholder(variable_name='history'),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "### OLDER WAY OF CREATING PROMPT TEMPLATE - USE AS EXAMPLE\n",
    "template = \"You are a helpful data analyst for answering questions related to job listings. \"\n",
    "\" If you don't know the answer, just say that you don't know, don't try to make up an answer. \"\n",
    "\" ---------------- \"\n",
    "\"{agent_scratchpad}\\n\"\n",
    "    \n",
    "# Generate the prompt template using the provided or default template string function\n",
    "prompt_template = OpenAIFunctionsAgent.create_prompt(\n",
    "    system_message=SystemMessage(template),\n",
    "    extra_prompt_messages=[MessagesPlaceholder(variable_name=\"history\")],\n",
    ")\n",
    "\n",
    "# prompt_template.get_prompts()\n",
    "prompt_template.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['agent_scratchpad', 'history', 'input'], input_types={'history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]], 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessage(content=\"You are a helpful data analyst for answering questions related to job listings. If you don't know the answer, just say that you don't know, don't try to make up an answer.\"), MessagesPlaceholder(variable_name='history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')), MessagesPlaceholder(variable_name='agent_scratchpad')])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Manually construct the prompts for the agent\n",
    "\n",
    "system_prompt = (\"You are a helpful data analyst for answering questions related to job listings.\"\n",
    "                \" If you don't know the answer, just say that you don't know, don't try to make up an answer.\")\n",
    "prompt_messages = [SystemMessage(system_prompt),\n",
    "                    MessagesPlaceholder(variable_name=\"history\"),\n",
    "                    HumanMessagePromptTemplate.from_template(\"{input}\",),\n",
    "                    MessagesPlaceholder(variable_name='agent_scratchpad')]\n",
    "\n",
    "agent_prompt = ChatPromptTemplate.from_messages(prompt_messages)\n",
    "agent_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentExecutor(memory=ConversationBufferMemory(return_messages=True), verbose=True, agent=RunnableMultiActionAgent(runnable=RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'history', 'input'], input_types={'history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]], 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessage(content=\"You are a helpful data analyst for answering questions related to job listings. If you don't know the answer, just say that you don't know, don't try to make up an answer.\"), MessagesPlaceholder(variable_name='history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x3252fb2e0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x324a5a770>, model_name='gpt-4o-mini', temperature=0.0, openai_api_key=SecretStr('**********'), openai_proxy=''), kwargs={'tools': [{'type': 'function', 'function': {'name': 'search_listings', 'description': 'Search job listings for relevant information.', 'parameters': {'type': 'object', 'properties': {'query': {'description': 'query to look up in retriever', 'type': 'string'}}, 'required': ['query']}}}]})\n",
       "| OpenAIToolsAgentOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[Tool(name='search_listings', description='Search job listings for relevant information.', args_schema=<class 'langchain.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x16bd72b90>, retriever=SelfQueryRetriever(vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x31adc12a0>, query_constructor=RunnableBinding(bound=FewShotPromptTemplate(input_variables=['query'], examples=[{'i': 1, 'data_source': '```json\\n{{\\n    \"content\": \"Lyrics of a song\",\\n    \"attributes\": {{\\n        \"artist\": {{\\n            \"type\": \"string\",\\n            \"description\": \"Name of the song artist\"\\n        }},\\n        \"length\": {{\\n            \"type\": \"integer\",\\n            \"description\": \"Length of the song in seconds\"\\n        }},\\n        \"genre\": {{\\n            \"type\": \"string\",\\n            \"description\": \"The song genre, one of \"pop\", \"rock\" or \"rap\"\"\\n        }}\\n    }}\\n}}\\n```', 'user_query': 'What are songs by Taylor Swift or Katy Perry about teenage romance under 3 minutes long in the dance pop genre', 'structured_request': '```json\\n{{\\n    \"query\": \"teenager love\",\\n    \"filter\": \"and(or(eq(\\\\\"artist\\\\\", \\\\\"Taylor Swift\\\\\"), eq(\\\\\"artist\\\\\", \\\\\"Katy Perry\\\\\")), lt(\\\\\"length\\\\\", 180), eq(\\\\\"genre\\\\\", \\\\\"pop\\\\\"))\"\\n}}\\n```'}, {'i': 2, 'data_source': '```json\\n{{\\n    \"content\": \"Lyrics of a song\",\\n    \"attributes\": {{\\n        \"artist\": {{\\n            \"type\": \"string\",\\n            \"description\": \"Name of the song artist\"\\n        }},\\n        \"length\": {{\\n            \"type\": \"integer\",\\n            \"description\": \"Length of the song in seconds\"\\n        }},\\n        \"genre\": {{\\n            \"type\": \"string\",\\n            \"description\": \"The song genre, one of \"pop\", \"rock\" or \"rap\"\"\\n        }}\\n    }}\\n}}\\n```', 'user_query': 'What are songs that were not published on Spotify', 'structured_request': '```json\\n{{\\n    \"query\": \"\",\\n    \"filter\": \"NO_FILTER\"\\n}}\\n```'}, {'i': 3, 'data_source': '```json\\n{{\\n    \"content\": \"Lyrics of a song\",\\n    \"attributes\": {{\\n        \"artist\": {{\\n            \"type\": \"string\",\\n            \"description\": \"Name of the song artist\"\\n        }},\\n        \"length\": {{\\n            \"type\": \"integer\",\\n            \"description\": \"Length of the song in seconds\"\\n        }},\\n        \"genre\": {{\\n            \"type\": \"string\",\\n            \"description\": \"The song genre, one of \"pop\", \"rock\" or \"rap\"\"\\n        }}\\n    }}\\n}}\\n```', 'user_query': 'What are three songs about love', 'structured_request': '```json\\n{{\\n    \"query\": \"love\",\\n    \"filter\": \"NO_FILTER\",\\n    \"limit\": 2\\n}}\\n```'}], example_prompt=PromptTemplate(input_variables=['data_source', 'i', 'structured_request', 'user_query'], template='<< Example {i}. >>\\nData Source:\\n{data_source}\\n\\nUser Query:\\n{user_query}\\n\\nStructured Request:\\n{structured_request}\\n'), suffix='<< Example 4. >>\\nData Source:\\n```json\\n{{\\n    \"content\": \"Job listings\",\\n    \"attributes\": {{\\n    \"source\": {{\\n        \"description\": \"Category of source type. One of manual, applyall, or scraped\",\\n        \"type\": \"string\"\\n    }},\\n    \"trust_rank\": {{\\n        \"description\": \"Rank of the source of the document. Lower is better.\",\\n        \"type\": \"int\"\\n    }},\\n    \"file_name\": {{\\n        \"description\": \"Name of the file\",\\n        \"type\": \"string\"\\n    }},\\n    \"file_path\": {{\\n        \"description\": \"Path to the file\",\\n        \"type\": \"string\"\\n    }}\\n}}\\n}}\\n```\\n\\nUser Query:\\n{query}\\n\\nStructured Request:\\n', prefix='Your goal is to structure the user\\'s query to match the request schema provided below.\\n\\n<< Structured Request Schema >>\\nWhen responding use a markdown code snippet with a JSON object formatted in the following schema:\\n\\n```json\\n{{\\n    \"query\": string \\\\ text string to compare to document contents\\n    \"filter\": string \\\\ logical condition statement for filtering documents\\n    \"limit\": int \\\\ the number of documents to retrieve\\n}}\\n```\\n\\nThe query string should contain only text that is expected to match the contents of documents. Any conditions in the filter should not be mentioned in the query as well.\\n\\nA logical condition statement is composed of one or more comparison and logical operation statements.\\n\\nA comparison statement takes the form: `comp(attr, val)`:\\n- `comp` (eq | ne | gt | gte | lt | lte): comparator\\n- `attr` (string):  name of attribute to apply the comparison to\\n- `val` (string): is the comparison value\\n\\nA logical operation statement takes the form `op(statement1, statement2, ...)`:\\n- `op` (and | or): logical operator\\n- `statement1`, `statement2`, ... (comparison statements or logical operation statements): one or more statements to apply the operation to\\n\\nMake sure that you only use the comparators and logical operators listed above and no others.\\nMake sure that filters only refer to attributes that exist in the data source.\\nMake sure that filters only use the attributed names with its function names if there are functions applied on them.\\nMake sure that filters only use format `YYYY-MM-DD` when handling date data typed values.\\nMake sure that filters take into account the descriptions of attributes and only make comparisons that are feasible given the type of data being stored.\\nMake sure that filters are only used as needed. If there are no filters that should be applied return \"NO_FILTER\" for the filter value.\\nMake sure the `limit` is always an int value. It is an optional parameter so leave it blank if it does not make sense.\\n')\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x329ca3340>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x329ca16f0>, model_name='gpt-4o-mini', temperature=0.0, openai_api_key=SecretStr('**********'), openai_proxy='')\n",
       "| StructuredQueryOutputParser(ast_parse=<bound method Lark.parse of Lark(open('<string>'), parser='lalr', lexer='contextual', ...)>), config={'run_name': 'query_constructor'}), search_kwargs={'k': 8}, structured_query_translator=<langchain.retrievers.self_query.chroma.ChromaTranslator object at 0x329ca19c0>), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n'), coroutine=functools.partial(<function _aget_relevant_documents at 0x16bd72cb0>, retriever=SelfQueryRetriever(vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x31adc12a0>, query_constructor=RunnableBinding(bound=FewShotPromptTemplate(input_variables=['query'], examples=[{'i': 1, 'data_source': '```json\\n{{\\n    \"content\": \"Lyrics of a song\",\\n    \"attributes\": {{\\n        \"artist\": {{\\n            \"type\": \"string\",\\n            \"description\": \"Name of the song artist\"\\n        }},\\n        \"length\": {{\\n            \"type\": \"integer\",\\n            \"description\": \"Length of the song in seconds\"\\n        }},\\n        \"genre\": {{\\n            \"type\": \"string\",\\n            \"description\": \"The song genre, one of \"pop\", \"rock\" or \"rap\"\"\\n        }}\\n    }}\\n}}\\n```', 'user_query': 'What are songs by Taylor Swift or Katy Perry about teenage romance under 3 minutes long in the dance pop genre', 'structured_request': '```json\\n{{\\n    \"query\": \"teenager love\",\\n    \"filter\": \"and(or(eq(\\\\\"artist\\\\\", \\\\\"Taylor Swift\\\\\"), eq(\\\\\"artist\\\\\", \\\\\"Katy Perry\\\\\")), lt(\\\\\"length\\\\\", 180), eq(\\\\\"genre\\\\\", \\\\\"pop\\\\\"))\"\\n}}\\n```'}, {'i': 2, 'data_source': '```json\\n{{\\n    \"content\": \"Lyrics of a song\",\\n    \"attributes\": {{\\n        \"artist\": {{\\n            \"type\": \"string\",\\n            \"description\": \"Name of the song artist\"\\n        }},\\n        \"length\": {{\\n            \"type\": \"integer\",\\n            \"description\": \"Length of the song in seconds\"\\n        }},\\n        \"genre\": {{\\n            \"type\": \"string\",\\n            \"description\": \"The song genre, one of \"pop\", \"rock\" or \"rap\"\"\\n        }}\\n    }}\\n}}\\n```', 'user_query': 'What are songs that were not published on Spotify', 'structured_request': '```json\\n{{\\n    \"query\": \"\",\\n    \"filter\": \"NO_FILTER\"\\n}}\\n```'}, {'i': 3, 'data_source': '```json\\n{{\\n    \"content\": \"Lyrics of a song\",\\n    \"attributes\": {{\\n        \"artist\": {{\\n            \"type\": \"string\",\\n            \"description\": \"Name of the song artist\"\\n        }},\\n        \"length\": {{\\n            \"type\": \"integer\",\\n            \"description\": \"Length of the song in seconds\"\\n        }},\\n        \"genre\": {{\\n            \"type\": \"string\",\\n            \"description\": \"The song genre, one of \"pop\", \"rock\" or \"rap\"\"\\n        }}\\n    }}\\n}}\\n```', 'user_query': 'What are three songs about love', 'structured_request': '```json\\n{{\\n    \"query\": \"love\",\\n    \"filter\": \"NO_FILTER\",\\n    \"limit\": 2\\n}}\\n```'}], example_prompt=PromptTemplate(input_variables=['data_source', 'i', 'structured_request', 'user_query'], template='<< Example {i}. >>\\nData Source:\\n{data_source}\\n\\nUser Query:\\n{user_query}\\n\\nStructured Request:\\n{structured_request}\\n'), suffix='<< Example 4. >>\\nData Source:\\n```json\\n{{\\n    \"content\": \"Job listings\",\\n    \"attributes\": {{\\n    \"source\": {{\\n        \"description\": \"Category of source type. One of manual, applyall, or scraped\",\\n        \"type\": \"string\"\\n    }},\\n    \"trust_rank\": {{\\n        \"description\": \"Rank of the source of the document. Lower is better.\",\\n        \"type\": \"int\"\\n    }},\\n    \"file_name\": {{\\n        \"description\": \"Name of the file\",\\n        \"type\": \"string\"\\n    }},\\n    \"file_path\": {{\\n        \"description\": \"Path to the file\",\\n        \"type\": \"string\"\\n    }}\\n}}\\n}}\\n```\\n\\nUser Query:\\n{query}\\n\\nStructured Request:\\n', prefix='Your goal is to structure the user\\'s query to match the request schema provided below.\\n\\n<< Structured Request Schema >>\\nWhen responding use a markdown code snippet with a JSON object formatted in the following schema:\\n\\n```json\\n{{\\n    \"query\": string \\\\ text string to compare to document contents\\n    \"filter\": string \\\\ logical condition statement for filtering documents\\n    \"limit\": int \\\\ the number of documents to retrieve\\n}}\\n```\\n\\nThe query string should contain only text that is expected to match the contents of documents. Any conditions in the filter should not be mentioned in the query as well.\\n\\nA logical condition statement is composed of one or more comparison and logical operation statements.\\n\\nA comparison statement takes the form: `comp(attr, val)`:\\n- `comp` (eq | ne | gt | gte | lt | lte): comparator\\n- `attr` (string):  name of attribute to apply the comparison to\\n- `val` (string): is the comparison value\\n\\nA logical operation statement takes the form `op(statement1, statement2, ...)`:\\n- `op` (and | or): logical operator\\n- `statement1`, `statement2`, ... (comparison statements or logical operation statements): one or more statements to apply the operation to\\n\\nMake sure that you only use the comparators and logical operators listed above and no others.\\nMake sure that filters only refer to attributes that exist in the data source.\\nMake sure that filters only use the attributed names with its function names if there are functions applied on them.\\nMake sure that filters only use format `YYYY-MM-DD` when handling date data typed values.\\nMake sure that filters take into account the descriptions of attributes and only make comparisons that are feasible given the type of data being stored.\\nMake sure that filters are only used as needed. If there are no filters that should be applied return \"NO_FILTER\" for the filter value.\\nMake sure the `limit` is always an int value. It is an optional parameter so leave it blank if it does not make sense.\\n')\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x329ca3340>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x329ca16f0>, model_name='gpt-4o-mini', temperature=0.0, openai_api_key=SecretStr('**********'), openai_proxy='')\n",
       "| StructuredQueryOutputParser(ast_parse=<bound method Lark.parse of Lark(open('<string>'), parser='lalr', lexer='contextual', ...)>), config={'run_name': 'query_constructor'}), search_kwargs={'k': 8}, structured_query_translator=<langchain.retrievers.self_query.chroma.ChromaTranslator object at 0x329ca19c0>), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n'))])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Initialize the language model with the specified temperature\n",
    "llm = ChatOpenAI(temperature=0.0, model='gpt-4o-mini')#, api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Create the agent using the language model and tools\n",
    "agent = create_openai_tools_agent(llm, \n",
    "                                  tools, \n",
    "                                  agent_prompt)\n",
    "# Create the agent executor with conversation buffer memory\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, memory=ConversationBufferMemory(max_length=10,return_messages=True))\n",
    "agent_executor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `search_listings` with `{'query': 'data scientist skills required'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3moutputs to the task at hand.\n",
      "MS  degree in Statistics, Ma th, Data Analytics, or a related quantitative ﬁeld \n",
      "At least 3 years of post graduate professi onal experience in Advanced Data Science, su ch as predictive modeling,\n",
      "statistical analysi s, machine learning, text mining, geosp atial analytics, time series forecasting, optimization \n",
      "Demonstrated Experience with NLP and other components of AI\n",
      "Experience implementing AI so lutions\n",
      "Experience with one or more Advanced Data Science so ftware languages (Python, R, SAS)  \n",
      "Proven ability to deploy machine learning models from the research environment (Jupyter Notebooks) to production\n",
      "via procedural or pipeline approaches \n",
      "Experience with SQL and relational databases, query authoring and tuning as well as working familiarity with a variety\n",
      "of databases including Hadoop/Hive \n",
      "Experience with sp ark and data-frames in PyS park or Scala \n",
      "Strong problem-so lving skills; ability to pivo t complex data to answe r business questions. Proven ability to visu alize\n",
      "data for inﬂuencing. \n",
      "Comfortable with cloud-based platforms (AWS, Azure, Google) \n",
      "Experience with Google Analytics, Adobe Analytics, Optimizely a plus \n",
      "Privacy Policy Imprint\n",
      "Cookies Settings\n",
      "\n",
      "Data Scientist\n",
      "San Jose, CA, USA, San Jose, CA\n",
      "Full-time\n",
      "Company Description\n",
      "We are seeking a data scientist with at least 1 year of experience working with large data sets and 10 years of total\n",
      "professi onal experience. This role is expected to translate business objectives into actionable data analysi s and\n",
      "communicate ﬁndings clearly to technical and non-technical audiences\n",
      "Job Description\n",
      "Required\n",
      "• Analytical thinking;\n",
      "• Understanding of statistics fundamentals;\n",
      "• In-depth knowledge on the Hadoop stack (Ma p reduce, HDFS, Hive, Pig);\n",
      "• In-depth knowledge on machine learning methods;\n",
      "• Experience with scripting languages su ch as Python;\n",
      "• Understanding of main statistical methods;\n",
      "• Understanding of sampling techniques;\n",
      "• Understanding of descriptive and inferential statistics concepts;\n",
      "• Business domain experience in one of the following areas: retail, enterprise mobility, healthcare;\n",
      "Qualiﬁcations\n",
      "• B.Sc. degree in Computer Science, Engineering, Ma thematics, Statistics or related ﬁeld is required\n",
      "• M. Sc. / Ph.D degree in related ﬁeld is desirable.\n",
      "Additional Information\n",
      "All yo ur information will be kept conﬁdential according to EEO guidelines. Job Location\n",
      "Cookies Settings\n",
      "Powered by\n",
      " (Data Processor)\n",
      "Privacy Policy and Terms of Use\n",
      "\n",
      "Data Scientist\n",
      "San Jose, CA, USA, San Jose, CA\n",
      "Full-time\n",
      "Company Description\n",
      "We are seeking a data scientist with at least 1 year of experience working with large data sets and 10 years of total\n",
      "professi onal experience. This role is expected to translate business objectives into actionable data analysi s and\n",
      "communicate ﬁndings clearly to technical and non-technical audiences\n",
      "Job Description\n",
      "Required\n",
      "• Analytical thinking;\n",
      "• Understanding of statistics fundamentals;\n",
      "• In-depth knowledge on the Hadoop stack (Ma p reduce, HDFS, Hive, Pig);\n",
      "• In-depth knowledge on machine learning methods;\n",
      "• Experience with scripting languages su ch as Python;\n",
      "• Understanding of main statistical methods;\n",
      "• Understanding of sampling techniques;\n",
      "• Understanding of descriptive and inferential statistics concepts;\n",
      "• Business domain experience in one of the following areas: retail, enterprise mobility, healthcare;\n",
      "Qualiﬁcations\n",
      "• B.Sc. degree in Computer Science, Engineering, Ma thematics, Statistics or related ﬁeld is required\n",
      "• M. Sc. / Ph.D degree in related ﬁeld is desirable.\n",
      "Additional Information\n",
      "All yo ur information will be kept conﬁdential according to EEO guidelines. Job Location\n",
      "Cookies Settings\n",
      "Powered by\n",
      " (Data Processor)\n",
      "Privacy Policy and Terms of Use\n",
      "\n",
      "Data Scientist Opportunity - NY\n",
      "New York, NY\n",
      "Full-time\n",
      "Job Description\n",
      "As a Data Scientist you will be collaborating across the organization, focusing on the data collection from land-based,\n",
      "web-based, social media, and mobile platforms, as well as the CRM practice. \n",
      "Working on a wide variety of initiatives, you will analyze massive amounts of data captured daily, and will build reporting\n",
      "solutions and develop visualizations to enable decision-making.\n",
      "The Data Scientist will be responsible for a wide variety of technology-driven, data-centric practices, including:\n",
      "Implementation and maintenance of analytics algorithms in a production setting.\n",
      "Development and implementation of analytics reporting and visualization dashboards.\n",
      "Development and support of database applications.\n",
      "Qualiﬁcations\n",
      "Requirements:\n",
      "Distinguished academic record, Bachelor’s degree,\n",
      "Strong mathematical background. Knowledge of statistics.\n",
      "2-5 years of actual Data Scientist experience.\n",
      "SQL experience: should have exposure to one of MySQL, Oracle, Hive, Shark, Presto.\n",
      "Programming: well versed in one of the following programming languages: Python, R, Ruby, Java, C++.\n",
      "Data Visualization on the web. Frontend, Visualization, JavaScript, D3, Dygraphs, Google Charts.\n",
      "Also Helpful (NOT Required): \n",
      "Experience with NoSQL (such as MongoDB, Hadoop)\n",
      "Additional Information\n",
      "All your information will be kept conﬁdential according to EEO guidelines.\n",
      "Cookies Settings\n",
      "\n",
      "Data Scientist\n",
      "Employees can work remotely\n",
      "Contract\n",
      "Company Description\n",
      "Enterprise client is looking for an Experienced Data Scientist\n",
      "Job Description\n",
      "Our team is looking for a Data Scientis for our enterprise client. They will be expected to:\n",
      "- Analyze large, complex datasets to identify trends, patterns, and insights\n",
      "- Develop and implement predictive models and machine learning algorithms\n",
      "- Collaborate with cross-f unctional teams to understand business requirements and translate them into data so lutions\n",
      "- Design and conduct experiments to test hyp otheses and validate models\n",
      "- Communicate ﬁndings and insights to stakeholders through data visu alization and reports\n",
      "- Continuously monitor model performance and make improvements as necessa ry\n",
      "- Stay up-to-date with the latest advancements in data science and machine learning\n",
      " \n",
      "Qualiﬁcations\n",
      "Requirements:\n",
      "- 5+ years of related experience as a Data Scientist, Product Scientist, Decision Scientist, or Research Scientist\n",
      "- Write documents /presentations for stakeholders and analysi s\n",
      "- Experimentation focused on A/B test resu lts\n",
      "- SQL\n",
      "- Programming languages su ch as Python or R\n",
      "- Code versioning so ftware (Git)\n",
      "- NLP exp with embedding or transformer\n",
      "- Statistical modeling\n",
      "- Ma chine learning\n",
      "- Deep learning (including large language models and/or computer vision)\n",
      "- Data pipeline engineering\n",
      "- Mo del deploym ent\n",
      "- Mu st be able to query data and make recommendations\n",
      "Privacy Policy\n",
      "Cookies Settings Powered by\n",
      " (Data Processor)\n",
      "Privacy Policy and Terms of Use\n",
      "\n",
      "opportunities to apply new techniques to our e-commerce challenges.\n",
      "Qualiﬁcations\n",
      "Experience:  5+ years of hands-on experience in data science, machine learning, or a related role.\n",
      "Technical Skills:\n",
      "Proﬁciency in Python and SQL.\n",
      "Experience with machine learning frameworks and libraries (e.g., TensorFlow , PyT orch, Scikit-learn).\n",
      "Strong understanding of statistical methods and data analysis techniques.\n",
      "Familiarity with data manipulation and analysis tools (e.g., pandas, NumPy).\n",
      "Experience with data visualization frameworks and tools (e.g., Matplotlib, Seaborn) is a plus.\n",
      "Analytical Mindset:  Strong problem-solving skills with the ability to translate complex data into actionable\n",
      "insights.\n",
      "Communication:  Excellent written and verbal communication skills, with the ability to explain technical\n",
      "concepts to non-technical stakeholders.\n",
      "Team Player:  Collaborative spirit with a proactive attitude and the ability to work independently when\n",
      "required.\n",
      "We are an equal opportunity employer/minority/female/disability/protected veteran.\n",
      "\n",
      "Data Scientist\n",
      "Arlington, Virginia, United States, Remote\n",
      "Excella is a leading provider of Agile software development and data and analytics solutions to clients in the\n",
      "federal, commercial and non-proﬁt sectors. W e believe that great work leads to great things –- our experts\n",
      "measure success by the positive impact we make on our clients, community , and colleagues. W e are growing\n",
      "fast and need passionate, innovative people who love working with technology and are ready to make an impact.\n",
      "Here's what you can expect from us:\n",
      "Workplace sites look dif ferent for everyone – whether it’ s your home or the ofﬁce, we believe in a ﬂexible\n",
      "work/life balance that supports you regardless of your location. W e offer a home ofﬁce allowance that can\n",
      "be used for home ofﬁce furniture/equipment, a daily pass for a coworking space, etc. Our commute\n",
      "reimbursement plan has you covered for whether you bike, Metro, or drive to work.\n",
      "We offer top of industry medical, dental, and vision beneﬁts with multiple options to choose from such as an\n",
      "employer-contributed health savings account, infertility coverage, and orthodontia so you can select the\n",
      "plan that works best for you.\n",
      "Regardless of what stage of life you’re in, Excella wants to support you. W e provide 8 weeks of Parental\n",
      "Leave, discounted pet insurance, and a Care.com membership with 3 back-up emergency child or elder\n",
      "care days annually – all available to you on your ﬁrst day .\n",
      "Starting day one, every employee is bonus eligible and receives 15 days of paid vacation, 6 federal\n",
      "holidays, and 4 ﬂoating holidays.\n",
      "Doing your best work means having the best tools! Excella’ s TechEleX program provides you with multiple\n",
      "options to suit your technology needs. Choose between a variety of Mac or PC devices, and to ensure your\n",
      "hardware remains current, at the end of a 3-year period Excella will replace your existing computer with a\n",
      "new model from the program. Plus, we’ll even give you the original device to keep for your personal use!\n",
      "Excella provides a W orkplace Allowance to of fset both the costs to maintain a distributed work environment\n",
      "and to enhance your workplace wellness. Excella will reimburse all full-time Excellians for up to $500 in\n",
      "expenses incurred during the calendar year .\n",
      "Diversity and inclusion matter . Excella created and continues to support employee led-afﬁnity groups and\n",
      "the Inclusion Diversity Equity Ambassador (IDEA) team, a cross-functional employee-led initiative to\n",
      "continually foster innovation and increase inclusion within Excella.\n",
      "We'll invest in your career by providing 3 days of paid professional development every year , including travel\n",
      "and registration fees to attend classes and conferences.\n",
      "We encourage mindfulness and overall well-being through employee wellness events, a HeadSpace\n",
      "membership, as well as access to TalkSpace and mental health coverage through our medical plans.\n",
      "Overview\n",
      "The Data Scientist is responsible for using advanced statistical, algorithmic, machine learning, data mining and\n",
      "visualization techniques to help advance and complete client projects. The Data Scientist must also be able to\n",
      "communicate complex quantitative analyses in a clear , precise, and actionable manner to management and\n",
      "executive level audiences.\n",
      "Responsibilities\n",
      "Working directly with client stakeholders to understand and deﬁne analysis objectives and then translate\n",
      "these into actionable results. Obtaining data from multiple, disparate data sources including structured, semi-structured and unstructured\n",
      "data.\n",
      "Using machine learning and data mining technique to understand the patterns in large volumes of data,\n",
      "identify relationships detect data anomalies, and classify data sets.\n",
      "Working with data integration developers to assess data quality and deﬁne data processing business rules\n",
      "for cleansing, aggregation, enhancement etc. support analysis and predictive modeling activities.\n",
      "Designing and building algorithms and predictive models using techniques such as linear and logistic\n",
      "regression, support vector machines, ensemble models (random forest and/or gradient boosted trees),\n",
      "neural networks, and clustering techniques.\n",
      "Deploying predictive models and integrating them into business processes and applications.\n",
      "Validating and optimizing model performance upon deployment and tracking over time as necessary .\n",
      "Presenting complex analysis results tailored to dif ferent audiences (e.g. technical, manager , executive) in a\n",
      "highly consumable and actionable form including the use of data visualizations.\n",
      "Qualiﬁcations\n",
      "T echnical:\n",
      "\n",
      "Data Scientist\n",
      "at BrightAI (View all jobs)\n",
      "United States (Remote)\n",
      "BrightAI, at the forefront of technological advancement, seeks a proﬁcient Data Scientist to unravel insights from complex datasets,\n",
      "employing advanced analytics and machine learning techniques. Our mission is to redeﬁne intelligent automation, and we are expanding\n",
      "our team to welcome a talented and technically adept individual who is passionate about pushing the boundaries of innovation. As we\n",
      "continue to push the boundaries of what's possible, we are looking for a skilled Data Scientist who shares our passion for harnessing\n",
      "data's potential to shape the future.\n",
      "As a Data Scientist at BrightAI, you will play a pivotal role in extracting meaningful insights from diverse datasets, employing advanced\n",
      "analytics and machine learning techniques. You will collaborate with cross-functional teams to develop data-driven solutions that\n",
      "contribute to the advancement of our cutting-edge projects. This position oﬀers an exciting opportunity to work at the intersection of data\n",
      "science, artiﬁcial intelligence, and innovative technologies.\n",
      "Key Responsibilities:\n",
      "Apply statistical analysis and machine learning techniques to extract actionable insights from complex datasets\n",
      "Develop predictive models and algorithms to solve business challenges and optimize processes\n",
      "Explore and preprocess large datasets to uncover hidden patterns and trends\n",
      "Create compelling visualizations to communicate insights eﬀectively to both technical and non-technical stakeholders\n",
      "Collaborate with data engineers and software developers to implement and deploy machine learning models into production\n",
      "environments\n",
      "Continuously optimize and reﬁne models to enhance accuracy and eﬃciency\n",
      "Identify relevant features and variables to improve model performance and contribute to feature engineering strategies\n",
      "Work closely with interdisciplinary teams, including software developers, engineers, and domain experts, to integrate data science\n",
      "solutions into broader projects\n",
      "Adhere to data governance standards, ensuring the responsible and ethical use of data throughout the development lifecycle\n",
      "Stay abreast of the latest developments in data science, machine learning, and related ﬁelds, applying new techniques to solve\n",
      "complex problems\n",
      "Qualiﬁcations:\n",
      "7+ years of experience in data science (Data Analyst or Data Scientist)\n",
      "Master's or Ph.D. in Data Science, Computer Science, Statistics, or a related ﬁeld\n",
      "Proven experience in data science, statistical analysis, and machine learning including pattern recognition and predictive modeling\n",
      "Proﬁciency in programming languages such as Python or SQL\n",
      "Strong understanding of data manipulation, feature engineering, and model evaluation techniques\n",
      "Experience with machine learning frameworks (e.g., TensorFlow, PyTorch) is a plus\n",
      "Excellent communication skills to convey complex ﬁndings and insights to diverse audiences\n",
      "Ability to work collaboratively in a fast-paced, innovative environment\n",
      "Bonus Criteria:\n",
      "Candidates with the following additional qualiﬁcations and experiences will be given special consideration:\n",
      "Experience with big data technologies and distributed computing\n",
      "Continued education with professional certiﬁcations\n",
      "Knowledge of natural language processing (NLP) and deep learning techniques.\n",
      "Background in developing data-driven solutions for real-world applications\n",
      "Contributions to open-source projects or active participation in the data science community #li-remote\u001b[0m\u001b[32;1m\u001b[1;3mThe skills required for the role of a data scientist typically include:\n",
      "\n",
      "1. **Educational Background**:\n",
      "   - A degree in Statistics, Mathematics, Data Analytics, Computer Science, Engineering, or a related quantitative field. Advanced degrees (M.Sc. or Ph.D.) are often desirable.\n",
      "\n",
      "2. **Technical Skills**:\n",
      "   - Proficiency in programming languages such as Python, R, or SQL.\n",
      "   - Experience with machine learning frameworks and libraries (e.g., TensorFlow, PyTorch, Scikit-learn).\n",
      "   - Knowledge of statistical methods and data analysis techniques.\n",
      "   - Familiarity with data manipulation and analysis tools (e.g., pandas, NumPy).\n",
      "   - Experience with data visualization tools and frameworks (e.g., Matplotlib, Seaborn, D3.js).\n",
      "   - Understanding of big data technologies (e.g., Hadoop, Spark) and distributed computing.\n",
      "\n",
      "3. **Machine Learning and Statistical Analysis**:\n",
      "   - In-depth knowledge of machine learning methods and algorithms.\n",
      "   - Experience in developing and deploying predictive models.\n",
      "   - Strong understanding of statistical fundamentals, including descriptive and inferential statistics.\n",
      "\n",
      "4. **Data Handling Skills**:\n",
      "   - Experience with SQL and relational databases, as well as familiarity with NoSQL databases.\n",
      "   - Ability to work with large datasets and perform data cleaning and preprocessing.\n",
      "\n",
      "5. **Analytical and Problem-Solving Skills**:\n",
      "   - Strong analytical thinking and problem-solving abilities.\n",
      "   - Ability to translate complex data into actionable insights.\n",
      "\n",
      "6. **Communication Skills**:\n",
      "   - Excellent written and verbal communication skills to convey findings to both technical and non-technical audiences.\n",
      "   - Experience in creating visualizations to communicate insights effectively.\n",
      "\n",
      "7. **Domain Knowledge**:\n",
      "   - Business domain experience in areas such as retail, healthcare, or enterprise mobility can be beneficial.\n",
      "\n",
      "8. **Collaboration and Teamwork**:\n",
      "   - Ability to work collaboratively with cross-functional teams and stakeholders.\n",
      "\n",
      "9. **Continuous Learning**:\n",
      "   - Staying updated with the latest advancements in data science and machine learning.\n",
      "\n",
      "These skills can vary based on specific job requirements and the industry in which the data scientist is working.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['input', 'history', 'output'])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = agent_executor.invoke({'input':\"What skills are required for the role of a data scientist?\"})\n",
    "result.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The skills required for the role of a data scientist typically include:\n",
      "\n",
      "1. **Educational Background**:\n",
      "   - A degree in Statistics, Mathematics, Data Analytics, Computer Science, Engineering, or a related quantitative field. Advanced degrees (M.Sc. or Ph.D.) are often desirable.\n",
      "\n",
      "2. **Technical Skills**:\n",
      "   - Proficiency in programming languages such as Python, R, or SQL.\n",
      "   - Experience with machine learning frameworks and libraries (e.g., TensorFlow, PyTorch, Scikit-learn).\n",
      "   - Knowledge of statistical methods and data analysis techniques.\n",
      "   - Familiarity with data manipulation and analysis tools (e.g., pandas, NumPy).\n",
      "   - Experience with data visualization tools and frameworks (e.g., Matplotlib, Seaborn, D3.js).\n",
      "   - Understanding of big data technologies (e.g., Hadoop, Spark) and distributed computing.\n",
      "\n",
      "3. **Machine Learning and Statistical Analysis**:\n",
      "   - In-depth knowledge of machine learning methods and algorithms.\n",
      "   - Experience in developing and deploying predictive models.\n",
      "   - Strong understanding of statistical fundamentals, including descriptive and inferential statistics.\n",
      "\n",
      "4. **Data Handling Skills**:\n",
      "   - Experience with SQL and relational databases, as well as familiarity with NoSQL databases.\n",
      "   - Ability to work with large datasets and perform data cleaning and preprocessing.\n",
      "\n",
      "5. **Analytical and Problem-Solving Skills**:\n",
      "   - Strong analytical thinking and problem-solving abilities.\n",
      "   - Ability to translate complex data into actionable insights.\n",
      "\n",
      "6. **Communication Skills**:\n",
      "   - Excellent written and verbal communication skills to convey findings to both technical and non-technical audiences.\n",
      "   - Experience in creating visualizations to communicate insights effectively.\n",
      "\n",
      "7. **Domain Knowledge**:\n",
      "   - Business domain experience in areas such as retail, healthcare, or enterprise mobility can be beneficial.\n",
      "\n",
      "8. **Collaboration and Teamwork**:\n",
      "   - Ability to work collaboratively with cross-functional teams and stakeholders.\n",
      "\n",
      "9. **Continuous Learning**:\n",
      "   - Staying updated with the latest advancements in data science and machine learning.\n",
      "\n",
      "These skills can vary based on specific job requirements and the industry in which the data scientist is working.\n"
     ]
    }
   ],
   "source": [
    "print(result['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Step: creating custom retrieval tool \n",
    "- Including trust ranks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Do: Add function for scraping ONET and save to Vector DB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dojo-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
